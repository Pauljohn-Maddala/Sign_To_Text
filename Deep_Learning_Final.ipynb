{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a68e981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b3f617d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.530803</td>\n",
       "      <td>0.581163</td>\n",
       "      <td>-1.472346e-06</td>\n",
       "      <td>0.413990</td>\n",
       "      <td>0.501149</td>\n",
       "      <td>-0.018073</td>\n",
       "      <td>0.355407</td>\n",
       "      <td>0.369223</td>\n",
       "      <td>-0.029657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057639</td>\n",
       "      <td>0.605741</td>\n",
       "      <td>0.320499</td>\n",
       "      <td>-0.091212</td>\n",
       "      <td>0.588447</td>\n",
       "      <td>0.400885</td>\n",
       "      <td>-0.071050</td>\n",
       "      <td>0.594126</td>\n",
       "      <td>0.455363</td>\n",
       "      <td>-0.044118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.503664</td>\n",
       "      <td>0.616673</td>\n",
       "      <td>-1.548741e-06</td>\n",
       "      <td>0.377512</td>\n",
       "      <td>0.536617</td>\n",
       "      <td>-0.016148</td>\n",
       "      <td>0.317852</td>\n",
       "      <td>0.408111</td>\n",
       "      <td>-0.028432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057488</td>\n",
       "      <td>0.561715</td>\n",
       "      <td>0.359349</td>\n",
       "      <td>-0.085140</td>\n",
       "      <td>0.546541</td>\n",
       "      <td>0.440563</td>\n",
       "      <td>-0.067003</td>\n",
       "      <td>0.551058</td>\n",
       "      <td>0.498263</td>\n",
       "      <td>-0.044481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0.267808</td>\n",
       "      <td>0.670679</td>\n",
       "      <td>-8.506087e-07</td>\n",
       "      <td>0.187360</td>\n",
       "      <td>0.610215</td>\n",
       "      <td>-0.020350</td>\n",
       "      <td>0.141140</td>\n",
       "      <td>0.503103</td>\n",
       "      <td>-0.030225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043488</td>\n",
       "      <td>0.369881</td>\n",
       "      <td>0.461587</td>\n",
       "      <td>-0.075160</td>\n",
       "      <td>0.362212</td>\n",
       "      <td>0.517269</td>\n",
       "      <td>-0.059621</td>\n",
       "      <td>0.349507</td>\n",
       "      <td>0.565708</td>\n",
       "      <td>-0.036153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>0.289091</td>\n",
       "      <td>0.751779</td>\n",
       "      <td>-1.795283e-06</td>\n",
       "      <td>0.167962</td>\n",
       "      <td>0.654705</td>\n",
       "      <td>-0.030267</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.499485</td>\n",
       "      <td>-0.048589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059609</td>\n",
       "      <td>0.393687</td>\n",
       "      <td>0.455553</td>\n",
       "      <td>-0.107050</td>\n",
       "      <td>0.365366</td>\n",
       "      <td>0.547497</td>\n",
       "      <td>-0.087988</td>\n",
       "      <td>0.356335</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>-0.058007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0.285160</td>\n",
       "      <td>0.762803</td>\n",
       "      <td>-1.769840e-06</td>\n",
       "      <td>0.161197</td>\n",
       "      <td>0.667723</td>\n",
       "      <td>-0.030836</td>\n",
       "      <td>0.094453</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>-0.048447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059550</td>\n",
       "      <td>0.388296</td>\n",
       "      <td>0.466932</td>\n",
       "      <td>-0.105277</td>\n",
       "      <td>0.361084</td>\n",
       "      <td>0.560643</td>\n",
       "      <td>-0.085365</td>\n",
       "      <td>0.352804</td>\n",
       "      <td>0.623975</td>\n",
       "      <td>-0.055310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class        x1        y1            z1        x2        y2        z2  \\\n",
       "0     A  0.530803  0.581163 -1.472346e-06  0.413990  0.501149 -0.018073   \n",
       "1     A  0.503664  0.616673 -1.548741e-06  0.377512  0.536617 -0.016148   \n",
       "2     A  0.267808  0.670679 -8.506087e-07  0.187360  0.610215 -0.020350   \n",
       "3     A  0.289091  0.751779 -1.795283e-06  0.167962  0.654705 -0.030267   \n",
       "4     A  0.285160  0.762803 -1.769840e-06  0.161197  0.667723 -0.030836   \n",
       "\n",
       "         x3        y3        z3  ...       z18       x19       y19       z19  \\\n",
       "0  0.355407  0.369223 -0.029657  ... -0.057639  0.605741  0.320499 -0.091212   \n",
       "1  0.317852  0.408111 -0.028432  ... -0.057488  0.561715  0.359349 -0.085140   \n",
       "2  0.141140  0.503103 -0.030225  ... -0.043488  0.369881  0.461587 -0.075160   \n",
       "3  0.100007  0.499485 -0.048589  ... -0.059609  0.393687  0.455553 -0.107050   \n",
       "4  0.094453  0.512100 -0.048447  ... -0.059550  0.388296  0.466932 -0.105277   \n",
       "\n",
       "        x20       y20       z20       x21       y21       z21  \n",
       "0  0.588447  0.400885 -0.071050  0.594126  0.455363 -0.044118  \n",
       "1  0.546541  0.440563 -0.067003  0.551058  0.498263 -0.044481  \n",
       "2  0.362212  0.517269 -0.059621  0.349507  0.565708 -0.036153  \n",
       "3  0.365366  0.547497 -0.087988  0.356335  0.612805 -0.058007  \n",
       "4  0.361084  0.560643 -0.085365  0.352804  0.623975 -0.055310  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"coords.csv\",index_col=False)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8986b64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12366</th>\n",
       "      <td>F</td>\n",
       "      <td>0.544936</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>-1.854814e-07</td>\n",
       "      <td>0.427920</td>\n",
       "      <td>0.634468</td>\n",
       "      <td>-0.031370</td>\n",
       "      <td>0.346604</td>\n",
       "      <td>0.511367</td>\n",
       "      <td>-0.052643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073663</td>\n",
       "      <td>0.871358</td>\n",
       "      <td>0.356649</td>\n",
       "      <td>-0.108195</td>\n",
       "      <td>0.893597</td>\n",
       "      <td>0.285638</td>\n",
       "      <td>-0.123308</td>\n",
       "      <td>0.887661</td>\n",
       "      <td>0.228563</td>\n",
       "      <td>-0.131590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55885</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.573280</td>\n",
       "      <td>0.853956</td>\n",
       "      <td>-6.157141e-07</td>\n",
       "      <td>0.495882</td>\n",
       "      <td>0.811011</td>\n",
       "      <td>-0.025449</td>\n",
       "      <td>0.438135</td>\n",
       "      <td>0.750147</td>\n",
       "      <td>-0.040570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030646</td>\n",
       "      <td>0.692039</td>\n",
       "      <td>0.682627</td>\n",
       "      <td>-0.060879</td>\n",
       "      <td>0.720518</td>\n",
       "      <td>0.656002</td>\n",
       "      <td>-0.065843</td>\n",
       "      <td>0.745053</td>\n",
       "      <td>0.631073</td>\n",
       "      <td>-0.061398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>B</td>\n",
       "      <td>0.667952</td>\n",
       "      <td>0.821011</td>\n",
       "      <td>6.201376e-07</td>\n",
       "      <td>0.543185</td>\n",
       "      <td>0.768543</td>\n",
       "      <td>-0.049613</td>\n",
       "      <td>0.450192</td>\n",
       "      <td>0.669005</td>\n",
       "      <td>-0.077175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076341</td>\n",
       "      <td>0.732392</td>\n",
       "      <td>0.385297</td>\n",
       "      <td>-0.100425</td>\n",
       "      <td>0.725890</td>\n",
       "      <td>0.316687</td>\n",
       "      <td>-0.109202</td>\n",
       "      <td>0.718197</td>\n",
       "      <td>0.257635</td>\n",
       "      <td>-0.115481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34102</th>\n",
       "      <td>O</td>\n",
       "      <td>0.594720</td>\n",
       "      <td>0.589327</td>\n",
       "      <td>-7.821563e-07</td>\n",
       "      <td>0.504903</td>\n",
       "      <td>0.581307</td>\n",
       "      <td>-0.021725</td>\n",
       "      <td>0.430946</td>\n",
       "      <td>0.542984</td>\n",
       "      <td>-0.032626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.502178</td>\n",
       "      <td>0.301569</td>\n",
       "      <td>-0.007132</td>\n",
       "      <td>0.452931</td>\n",
       "      <td>0.303505</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>0.419016</td>\n",
       "      <td>0.328406</td>\n",
       "      <td>-0.011252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21045</th>\n",
       "      <td>I</td>\n",
       "      <td>0.450404</td>\n",
       "      <td>0.788857</td>\n",
       "      <td>-1.156195e-06</td>\n",
       "      <td>0.296507</td>\n",
       "      <td>0.666854</td>\n",
       "      <td>-0.049063</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.503302</td>\n",
       "      <td>-0.069306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0.552315</td>\n",
       "      <td>0.254940</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.549412</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.549858</td>\n",
       "      <td>0.068836</td>\n",
       "      <td>0.027799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class        x1        y1            z1        x2        y2        z2  \\\n",
       "12366     F  0.544936  0.738639 -1.854814e-07  0.427920  0.634468 -0.031370   \n",
       "55885     Y  0.573280  0.853956 -6.157141e-07  0.495882  0.811011 -0.025449   \n",
       "2957      B  0.667952  0.821011  6.201376e-07  0.543185  0.768543 -0.049613   \n",
       "34102     O  0.594720  0.589327 -7.821563e-07  0.504903  0.581307 -0.021725   \n",
       "21045     I  0.450404  0.788857 -1.156195e-06  0.296507  0.666854 -0.049063   \n",
       "\n",
       "             x3        y3        z3  ...       z18       x19       y19  \\\n",
       "12366  0.346604  0.511367 -0.052643  ... -0.073663  0.871358  0.356649   \n",
       "55885  0.438135  0.750147 -0.040570  ... -0.030646  0.692039  0.682627   \n",
       "2957   0.450192  0.669005 -0.077175  ... -0.076341  0.732392  0.385297   \n",
       "34102  0.430946  0.542984 -0.032626  ...  0.001277  0.502178  0.301569   \n",
       "21045  0.223400  0.503302 -0.069306  ...  0.018939  0.552315  0.254940   \n",
       "\n",
       "            z19       x20       y20       z20       x21       y21       z21  \n",
       "12366 -0.108195  0.893597  0.285638 -0.123308  0.887661  0.228563 -0.131590  \n",
       "55885 -0.060879  0.720518  0.656002 -0.065843  0.745053  0.631073 -0.061398  \n",
       "2957  -0.100425  0.725890  0.316687 -0.109202  0.718197  0.257635 -0.115481  \n",
       "34102 -0.007132  0.452931  0.303505 -0.010894  0.419016  0.328406 -0.011252  \n",
       "21045  0.003705  0.549412  0.152141  0.008938  0.549858  0.068836  0.027799  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.sample(frac=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7a47123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dataset.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4259e29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauljohnmaddala/anaconda3/envs/tfenv/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the class labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "class_labels = dataset['class'].values.reshape(-1, 1)\n",
    "class_labels_encoded = encoder.fit_transform(class_labels)\n",
    "\n",
    "# Dropping the 'class' column from the dataset\n",
    "features = dataset.drop('class', axis=1)\n",
    "\n",
    "# Standardize the feature columns\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "71521d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since we don't have a time series, we will treat each coordinate set (x, y, z) as one time step.\n",
    "# This means we have 21 time steps with 3 features each.\n",
    "features_reshaped = features_scaled.reshape((features_scaled.shape[0], 21, 3))\n",
    "\n",
    "#features = features.to_numpy()\n",
    "\n",
    "#features_reshaped = features.reshape((features.shape[0], 21, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16940b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_reshaped, class_labels_encoded, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2bef0938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 1.2841 - accuracy: 0.6044 - val_loss: 0.6271 - val_accuracy: 0.7987\n",
      "Epoch 2/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.3075 - accuracy: 0.9051 - val_loss: 0.4156 - val_accuracy: 0.8545\n",
      "Epoch 3/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.2066 - accuracy: 0.9383 - val_loss: 0.2254 - val_accuracy: 0.9263\n",
      "Epoch 4/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.1546 - accuracy: 0.9545 - val_loss: 0.1218 - val_accuracy: 0.9646\n",
      "Epoch 5/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.1237 - accuracy: 0.9635 - val_loss: 0.1603 - val_accuracy: 0.9541\n",
      "Epoch 6/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.1071 - accuracy: 0.9693 - val_loss: 0.1432 - val_accuracy: 0.9543\n",
      "Epoch 7/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0953 - accuracy: 0.9731 - val_loss: 0.0926 - val_accuracy: 0.9754\n",
      "Epoch 8/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0870 - accuracy: 0.9749 - val_loss: 0.0773 - val_accuracy: 0.9801\n",
      "Epoch 9/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0796 - accuracy: 0.9766 - val_loss: 0.0761 - val_accuracy: 0.9810\n",
      "Epoch 10/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0724 - accuracy: 0.9790 - val_loss: 0.0890 - val_accuracy: 0.9738\n",
      "Epoch 11/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0679 - accuracy: 0.9804 - val_loss: 0.0817 - val_accuracy: 0.9792\n",
      "Epoch 12/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0679 - accuracy: 0.9795 - val_loss: 0.0622 - val_accuracy: 0.9852\n",
      "Epoch 13/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0587 - accuracy: 0.9822 - val_loss: 0.0743 - val_accuracy: 0.9817\n",
      "Epoch 14/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0543 - accuracy: 0.9844 - val_loss: 0.0728 - val_accuracy: 0.9809\n",
      "Epoch 15/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0527 - accuracy: 0.9849 - val_loss: 0.0637 - val_accuracy: 0.9845\n",
      "Epoch 16/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0509 - accuracy: 0.9847 - val_loss: 0.0643 - val_accuracy: 0.9847\n",
      "Epoch 17/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0457 - accuracy: 0.9859 - val_loss: 0.0580 - val_accuracy: 0.9861\n",
      "Epoch 18/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0518 - accuracy: 0.9850 - val_loss: 0.0565 - val_accuracy: 0.9856\n",
      "Epoch 19/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0392 - accuracy: 0.9878 - val_loss: 0.0613 - val_accuracy: 0.9831\n",
      "Epoch 20/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0408 - accuracy: 0.9879 - val_loss: 0.0919 - val_accuracy: 0.9735\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2912a9640>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model_Base = Sequential()\n",
    "model_Base.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "model_Base.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_Base.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_Base.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35ab31e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.35%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy_base = model_Base.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy_base*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9459227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12366</th>\n",
       "      <td>F</td>\n",
       "      <td>0.544936</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>-1.854814e-07</td>\n",
       "      <td>0.427920</td>\n",
       "      <td>0.634468</td>\n",
       "      <td>-0.031370</td>\n",
       "      <td>0.346604</td>\n",
       "      <td>0.511367</td>\n",
       "      <td>-0.052643</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073663</td>\n",
       "      <td>0.871358</td>\n",
       "      <td>0.356649</td>\n",
       "      <td>-0.108195</td>\n",
       "      <td>0.893597</td>\n",
       "      <td>0.285638</td>\n",
       "      <td>-0.123308</td>\n",
       "      <td>0.887661</td>\n",
       "      <td>0.228563</td>\n",
       "      <td>-0.131590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55885</th>\n",
       "      <td>Y</td>\n",
       "      <td>0.573280</td>\n",
       "      <td>0.853956</td>\n",
       "      <td>-6.157141e-07</td>\n",
       "      <td>0.495882</td>\n",
       "      <td>0.811011</td>\n",
       "      <td>-0.025449</td>\n",
       "      <td>0.438135</td>\n",
       "      <td>0.750147</td>\n",
       "      <td>-0.040570</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030646</td>\n",
       "      <td>0.692039</td>\n",
       "      <td>0.682627</td>\n",
       "      <td>-0.060879</td>\n",
       "      <td>0.720518</td>\n",
       "      <td>0.656002</td>\n",
       "      <td>-0.065843</td>\n",
       "      <td>0.745053</td>\n",
       "      <td>0.631073</td>\n",
       "      <td>-0.061398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>B</td>\n",
       "      <td>0.667952</td>\n",
       "      <td>0.821011</td>\n",
       "      <td>6.201376e-07</td>\n",
       "      <td>0.543185</td>\n",
       "      <td>0.768543</td>\n",
       "      <td>-0.049613</td>\n",
       "      <td>0.450192</td>\n",
       "      <td>0.669005</td>\n",
       "      <td>-0.077175</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076341</td>\n",
       "      <td>0.732392</td>\n",
       "      <td>0.385297</td>\n",
       "      <td>-0.100425</td>\n",
       "      <td>0.725890</td>\n",
       "      <td>0.316687</td>\n",
       "      <td>-0.109202</td>\n",
       "      <td>0.718197</td>\n",
       "      <td>0.257635</td>\n",
       "      <td>-0.115481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34102</th>\n",
       "      <td>O</td>\n",
       "      <td>0.594720</td>\n",
       "      <td>0.589327</td>\n",
       "      <td>-7.821563e-07</td>\n",
       "      <td>0.504903</td>\n",
       "      <td>0.581307</td>\n",
       "      <td>-0.021725</td>\n",
       "      <td>0.430946</td>\n",
       "      <td>0.542984</td>\n",
       "      <td>-0.032626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.502178</td>\n",
       "      <td>0.301569</td>\n",
       "      <td>-0.007132</td>\n",
       "      <td>0.452931</td>\n",
       "      <td>0.303505</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>0.419016</td>\n",
       "      <td>0.328406</td>\n",
       "      <td>-0.011252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21045</th>\n",
       "      <td>I</td>\n",
       "      <td>0.450404</td>\n",
       "      <td>0.788857</td>\n",
       "      <td>-1.156195e-06</td>\n",
       "      <td>0.296507</td>\n",
       "      <td>0.666854</td>\n",
       "      <td>-0.049063</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.503302</td>\n",
       "      <td>-0.069306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0.552315</td>\n",
       "      <td>0.254940</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.549412</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.549858</td>\n",
       "      <td>0.068836</td>\n",
       "      <td>0.027799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>D</td>\n",
       "      <td>0.509634</td>\n",
       "      <td>0.948830</td>\n",
       "      <td>-3.173397e-07</td>\n",
       "      <td>0.400603</td>\n",
       "      <td>0.900872</td>\n",
       "      <td>-0.003383</td>\n",
       "      <td>0.328751</td>\n",
       "      <td>0.810768</td>\n",
       "      <td>-0.024631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096039</td>\n",
       "      <td>0.373334</td>\n",
       "      <td>0.592465</td>\n",
       "      <td>-0.130136</td>\n",
       "      <td>0.300532</td>\n",
       "      <td>0.593418</td>\n",
       "      <td>-0.132346</td>\n",
       "      <td>0.263799</td>\n",
       "      <td>0.631488</td>\n",
       "      <td>-0.125428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54011</th>\n",
       "      <td>X</td>\n",
       "      <td>0.545854</td>\n",
       "      <td>0.544462</td>\n",
       "      <td>-3.782280e-07</td>\n",
       "      <td>0.478194</td>\n",
       "      <td>0.496838</td>\n",
       "      <td>-0.018536</td>\n",
       "      <td>0.433567</td>\n",
       "      <td>0.434329</td>\n",
       "      <td>-0.028777</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031976</td>\n",
       "      <td>0.622843</td>\n",
       "      <td>0.362683</td>\n",
       "      <td>-0.056083</td>\n",
       "      <td>0.594289</td>\n",
       "      <td>0.395130</td>\n",
       "      <td>-0.049286</td>\n",
       "      <td>0.582595</td>\n",
       "      <td>0.432643</td>\n",
       "      <td>-0.038324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>G</td>\n",
       "      <td>0.233454</td>\n",
       "      <td>0.449567</td>\n",
       "      <td>-3.105705e-07</td>\n",
       "      <td>0.178403</td>\n",
       "      <td>0.373647</td>\n",
       "      <td>-0.025916</td>\n",
       "      <td>0.174802</td>\n",
       "      <td>0.277639</td>\n",
       "      <td>-0.036873</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050362</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.331391</td>\n",
       "      <td>-0.087306</td>\n",
       "      <td>0.365192</td>\n",
       "      <td>0.363674</td>\n",
       "      <td>-0.071107</td>\n",
       "      <td>0.334583</td>\n",
       "      <td>0.396168</td>\n",
       "      <td>-0.047291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15626</th>\n",
       "      <td>G</td>\n",
       "      <td>0.128480</td>\n",
       "      <td>0.526536</td>\n",
       "      <td>4.246395e-07</td>\n",
       "      <td>0.064615</td>\n",
       "      <td>0.412387</td>\n",
       "      <td>-0.061215</td>\n",
       "      <td>0.095096</td>\n",
       "      <td>0.278999</td>\n",
       "      <td>-0.095136</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133550</td>\n",
       "      <td>0.382772</td>\n",
       "      <td>0.476533</td>\n",
       "      <td>-0.206874</td>\n",
       "      <td>0.305292</td>\n",
       "      <td>0.508867</td>\n",
       "      <td>-0.188753</td>\n",
       "      <td>0.240287</td>\n",
       "      <td>0.535760</td>\n",
       "      <td>-0.155334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54039</th>\n",
       "      <td>X</td>\n",
       "      <td>0.598929</td>\n",
       "      <td>0.591246</td>\n",
       "      <td>-3.639200e-07</td>\n",
       "      <td>0.523902</td>\n",
       "      <td>0.528148</td>\n",
       "      <td>-0.018382</td>\n",
       "      <td>0.480171</td>\n",
       "      <td>0.461707</td>\n",
       "      <td>-0.032044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042331</td>\n",
       "      <td>0.691529</td>\n",
       "      <td>0.390176</td>\n",
       "      <td>-0.067134</td>\n",
       "      <td>0.664799</td>\n",
       "      <td>0.425318</td>\n",
       "      <td>-0.059622</td>\n",
       "      <td>0.647095</td>\n",
       "      <td>0.465285</td>\n",
       "      <td>-0.047364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64042 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class        x1        y1            z1        x2        y2        z2  \\\n",
       "12366     F  0.544936  0.738639 -1.854814e-07  0.427920  0.634468 -0.031370   \n",
       "55885     Y  0.573280  0.853956 -6.157141e-07  0.495882  0.811011 -0.025449   \n",
       "2957      B  0.667952  0.821011  6.201376e-07  0.543185  0.768543 -0.049613   \n",
       "34102     O  0.594720  0.589327 -7.821563e-07  0.504903  0.581307 -0.021725   \n",
       "21045     I  0.450404  0.788857 -1.156195e-06  0.296507  0.666854 -0.049063   \n",
       "...     ...       ...       ...           ...       ...       ...       ...   \n",
       "6466      D  0.509634  0.948830 -3.173397e-07  0.400603  0.900872 -0.003383   \n",
       "54011     X  0.545854  0.544462 -3.782280e-07  0.478194  0.496838 -0.018536   \n",
       "14984     G  0.233454  0.449567 -3.105705e-07  0.178403  0.373647 -0.025916   \n",
       "15626     G  0.128480  0.526536  4.246395e-07  0.064615  0.412387 -0.061215   \n",
       "54039     X  0.598929  0.591246 -3.639200e-07  0.523902  0.528148 -0.018382   \n",
       "\n",
       "             x3        y3        z3  ...       z18       x19       y19  \\\n",
       "12366  0.346604  0.511367 -0.052643  ... -0.073663  0.871358  0.356649   \n",
       "55885  0.438135  0.750147 -0.040570  ... -0.030646  0.692039  0.682627   \n",
       "2957   0.450192  0.669005 -0.077175  ... -0.076341  0.732392  0.385297   \n",
       "34102  0.430946  0.542984 -0.032626  ...  0.001277  0.502178  0.301569   \n",
       "21045  0.223400  0.503302 -0.069306  ...  0.018939  0.552315  0.254940   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "6466   0.328751  0.810768 -0.024631  ... -0.096039  0.373334  0.592465   \n",
       "54011  0.433567  0.434329 -0.028777  ... -0.031976  0.622843  0.362683   \n",
       "14984  0.174802  0.277639 -0.036873  ... -0.050362  0.408700  0.331391   \n",
       "15626  0.095096  0.278999 -0.095136  ... -0.133550  0.382772  0.476533   \n",
       "54039  0.480171  0.461707 -0.032044  ... -0.042331  0.691529  0.390176   \n",
       "\n",
       "            z19       x20       y20       z20       x21       y21       z21  \n",
       "12366 -0.108195  0.893597  0.285638 -0.123308  0.887661  0.228563 -0.131590  \n",
       "55885 -0.060879  0.720518  0.656002 -0.065843  0.745053  0.631073 -0.061398  \n",
       "2957  -0.100425  0.725890  0.316687 -0.109202  0.718197  0.257635 -0.115481  \n",
       "34102 -0.007132  0.452931  0.303505 -0.010894  0.419016  0.328406 -0.011252  \n",
       "21045  0.003705  0.549412  0.152141  0.008938  0.549858  0.068836  0.027799  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "6466  -0.130136  0.300532  0.593418 -0.132346  0.263799  0.631488 -0.125428  \n",
       "54011 -0.056083  0.594289  0.395130 -0.049286  0.582595  0.432643 -0.038324  \n",
       "14984 -0.087306  0.365192  0.363674 -0.071107  0.334583  0.396168 -0.047291  \n",
       "15626 -0.206874  0.305292  0.508867 -0.188753  0.240287  0.535760 -0.155334  \n",
       "54039 -0.067134  0.664799  0.425318 -0.059622  0.647095  0.465285 -0.047364  \n",
       "\n",
       "[64042 rows x 64 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5ac0b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Encoding the class labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dc5c7d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>x4</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12366</th>\n",
       "      <td>0.544936</td>\n",
       "      <td>0.738639</td>\n",
       "      <td>-1.854814e-07</td>\n",
       "      <td>0.427920</td>\n",
       "      <td>0.634468</td>\n",
       "      <td>-0.031370</td>\n",
       "      <td>0.346604</td>\n",
       "      <td>0.511367</td>\n",
       "      <td>-0.052643</td>\n",
       "      <td>0.322795</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.073663</td>\n",
       "      <td>0.871358</td>\n",
       "      <td>0.356649</td>\n",
       "      <td>-0.108195</td>\n",
       "      <td>0.893597</td>\n",
       "      <td>0.285638</td>\n",
       "      <td>-0.123308</td>\n",
       "      <td>0.887661</td>\n",
       "      <td>0.228563</td>\n",
       "      <td>-0.131590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55885</th>\n",
       "      <td>0.573280</td>\n",
       "      <td>0.853956</td>\n",
       "      <td>-6.157141e-07</td>\n",
       "      <td>0.495882</td>\n",
       "      <td>0.811011</td>\n",
       "      <td>-0.025449</td>\n",
       "      <td>0.438135</td>\n",
       "      <td>0.750147</td>\n",
       "      <td>-0.040570</td>\n",
       "      <td>0.425703</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030646</td>\n",
       "      <td>0.692039</td>\n",
       "      <td>0.682627</td>\n",
       "      <td>-0.060879</td>\n",
       "      <td>0.720518</td>\n",
       "      <td>0.656002</td>\n",
       "      <td>-0.065843</td>\n",
       "      <td>0.745053</td>\n",
       "      <td>0.631073</td>\n",
       "      <td>-0.061398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>0.667952</td>\n",
       "      <td>0.821011</td>\n",
       "      <td>6.201376e-07</td>\n",
       "      <td>0.543185</td>\n",
       "      <td>0.768543</td>\n",
       "      <td>-0.049613</td>\n",
       "      <td>0.450192</td>\n",
       "      <td>0.669005</td>\n",
       "      <td>-0.077175</td>\n",
       "      <td>0.468831</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076341</td>\n",
       "      <td>0.732392</td>\n",
       "      <td>0.385297</td>\n",
       "      <td>-0.100425</td>\n",
       "      <td>0.725890</td>\n",
       "      <td>0.316687</td>\n",
       "      <td>-0.109202</td>\n",
       "      <td>0.718197</td>\n",
       "      <td>0.257635</td>\n",
       "      <td>-0.115481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34102</th>\n",
       "      <td>0.594720</td>\n",
       "      <td>0.589327</td>\n",
       "      <td>-7.821563e-07</td>\n",
       "      <td>0.504903</td>\n",
       "      <td>0.581307</td>\n",
       "      <td>-0.021725</td>\n",
       "      <td>0.430946</td>\n",
       "      <td>0.542984</td>\n",
       "      <td>-0.032626</td>\n",
       "      <td>0.386454</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001277</td>\n",
       "      <td>0.502178</td>\n",
       "      <td>0.301569</td>\n",
       "      <td>-0.007132</td>\n",
       "      <td>0.452931</td>\n",
       "      <td>0.303505</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>0.419016</td>\n",
       "      <td>0.328406</td>\n",
       "      <td>-0.011252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21045</th>\n",
       "      <td>0.450404</td>\n",
       "      <td>0.788857</td>\n",
       "      <td>-1.156195e-06</td>\n",
       "      <td>0.296507</td>\n",
       "      <td>0.666854</td>\n",
       "      <td>-0.049063</td>\n",
       "      <td>0.223400</td>\n",
       "      <td>0.503302</td>\n",
       "      <td>-0.069306</td>\n",
       "      <td>0.312203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018939</td>\n",
       "      <td>0.552315</td>\n",
       "      <td>0.254940</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.549412</td>\n",
       "      <td>0.152141</td>\n",
       "      <td>0.008938</td>\n",
       "      <td>0.549858</td>\n",
       "      <td>0.068836</td>\n",
       "      <td>0.027799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6466</th>\n",
       "      <td>0.509634</td>\n",
       "      <td>0.948830</td>\n",
       "      <td>-3.173397e-07</td>\n",
       "      <td>0.400603</td>\n",
       "      <td>0.900872</td>\n",
       "      <td>-0.003383</td>\n",
       "      <td>0.328751</td>\n",
       "      <td>0.810768</td>\n",
       "      <td>-0.024631</td>\n",
       "      <td>0.258079</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.096039</td>\n",
       "      <td>0.373334</td>\n",
       "      <td>0.592465</td>\n",
       "      <td>-0.130136</td>\n",
       "      <td>0.300532</td>\n",
       "      <td>0.593418</td>\n",
       "      <td>-0.132346</td>\n",
       "      <td>0.263799</td>\n",
       "      <td>0.631488</td>\n",
       "      <td>-0.125428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54011</th>\n",
       "      <td>0.545854</td>\n",
       "      <td>0.544462</td>\n",
       "      <td>-3.782280e-07</td>\n",
       "      <td>0.478194</td>\n",
       "      <td>0.496838</td>\n",
       "      <td>-0.018536</td>\n",
       "      <td>0.433567</td>\n",
       "      <td>0.434329</td>\n",
       "      <td>-0.028777</td>\n",
       "      <td>0.461022</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.031976</td>\n",
       "      <td>0.622843</td>\n",
       "      <td>0.362683</td>\n",
       "      <td>-0.056083</td>\n",
       "      <td>0.594289</td>\n",
       "      <td>0.395130</td>\n",
       "      <td>-0.049286</td>\n",
       "      <td>0.582595</td>\n",
       "      <td>0.432643</td>\n",
       "      <td>-0.038324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14984</th>\n",
       "      <td>0.233454</td>\n",
       "      <td>0.449567</td>\n",
       "      <td>-3.105705e-07</td>\n",
       "      <td>0.178403</td>\n",
       "      <td>0.373647</td>\n",
       "      <td>-0.025916</td>\n",
       "      <td>0.174802</td>\n",
       "      <td>0.277639</td>\n",
       "      <td>-0.036873</td>\n",
       "      <td>0.216330</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050362</td>\n",
       "      <td>0.408700</td>\n",
       "      <td>0.331391</td>\n",
       "      <td>-0.087306</td>\n",
       "      <td>0.365192</td>\n",
       "      <td>0.363674</td>\n",
       "      <td>-0.071107</td>\n",
       "      <td>0.334583</td>\n",
       "      <td>0.396168</td>\n",
       "      <td>-0.047291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15626</th>\n",
       "      <td>0.128480</td>\n",
       "      <td>0.526536</td>\n",
       "      <td>4.246395e-07</td>\n",
       "      <td>0.064615</td>\n",
       "      <td>0.412387</td>\n",
       "      <td>-0.061215</td>\n",
       "      <td>0.095096</td>\n",
       "      <td>0.278999</td>\n",
       "      <td>-0.095136</td>\n",
       "      <td>0.172362</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133550</td>\n",
       "      <td>0.382772</td>\n",
       "      <td>0.476533</td>\n",
       "      <td>-0.206874</td>\n",
       "      <td>0.305292</td>\n",
       "      <td>0.508867</td>\n",
       "      <td>-0.188753</td>\n",
       "      <td>0.240287</td>\n",
       "      <td>0.535760</td>\n",
       "      <td>-0.155334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54039</th>\n",
       "      <td>0.598929</td>\n",
       "      <td>0.591246</td>\n",
       "      <td>-3.639200e-07</td>\n",
       "      <td>0.523902</td>\n",
       "      <td>0.528148</td>\n",
       "      <td>-0.018382</td>\n",
       "      <td>0.480171</td>\n",
       "      <td>0.461707</td>\n",
       "      <td>-0.032044</td>\n",
       "      <td>0.511281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042331</td>\n",
       "      <td>0.691529</td>\n",
       "      <td>0.390176</td>\n",
       "      <td>-0.067134</td>\n",
       "      <td>0.664799</td>\n",
       "      <td>0.425318</td>\n",
       "      <td>-0.059622</td>\n",
       "      <td>0.647095</td>\n",
       "      <td>0.465285</td>\n",
       "      <td>-0.047364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64042 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        y1            z1        x2        y2        z2  \\\n",
       "12366  0.544936  0.738639 -1.854814e-07  0.427920  0.634468 -0.031370   \n",
       "55885  0.573280  0.853956 -6.157141e-07  0.495882  0.811011 -0.025449   \n",
       "2957   0.667952  0.821011  6.201376e-07  0.543185  0.768543 -0.049613   \n",
       "34102  0.594720  0.589327 -7.821563e-07  0.504903  0.581307 -0.021725   \n",
       "21045  0.450404  0.788857 -1.156195e-06  0.296507  0.666854 -0.049063   \n",
       "...         ...       ...           ...       ...       ...       ...   \n",
       "6466   0.509634  0.948830 -3.173397e-07  0.400603  0.900872 -0.003383   \n",
       "54011  0.545854  0.544462 -3.782280e-07  0.478194  0.496838 -0.018536   \n",
       "14984  0.233454  0.449567 -3.105705e-07  0.178403  0.373647 -0.025916   \n",
       "15626  0.128480  0.526536  4.246395e-07  0.064615  0.412387 -0.061215   \n",
       "54039  0.598929  0.591246 -3.639200e-07  0.523902  0.528148 -0.018382   \n",
       "\n",
       "             x3        y3        z3        x4  ...       z18       x19  \\\n",
       "12366  0.346604  0.511367 -0.052643  0.322795  ... -0.073663  0.871358   \n",
       "55885  0.438135  0.750147 -0.040570  0.425703  ... -0.030646  0.692039   \n",
       "2957   0.450192  0.669005 -0.077175  0.468831  ... -0.076341  0.732392   \n",
       "34102  0.430946  0.542984 -0.032626  0.386454  ...  0.001277  0.502178   \n",
       "21045  0.223400  0.503302 -0.069306  0.312203  ...  0.018939  0.552315   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "6466   0.328751  0.810768 -0.024631  0.258079  ... -0.096039  0.373334   \n",
       "54011  0.433567  0.434329 -0.028777  0.461022  ... -0.031976  0.622843   \n",
       "14984  0.174802  0.277639 -0.036873  0.216330  ... -0.050362  0.408700   \n",
       "15626  0.095096  0.278999 -0.095136  0.172362  ... -0.133550  0.382772   \n",
       "54039  0.480171  0.461707 -0.032044  0.511281  ... -0.042331  0.691529   \n",
       "\n",
       "            y19       z19       x20       y20       z20       x21       y21  \\\n",
       "12366  0.356649 -0.108195  0.893597  0.285638 -0.123308  0.887661  0.228563   \n",
       "55885  0.682627 -0.060879  0.720518  0.656002 -0.065843  0.745053  0.631073   \n",
       "2957   0.385297 -0.100425  0.725890  0.316687 -0.109202  0.718197  0.257635   \n",
       "34102  0.301569 -0.007132  0.452931  0.303505 -0.010894  0.419016  0.328406   \n",
       "21045  0.254940  0.003705  0.549412  0.152141  0.008938  0.549858  0.068836   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "6466   0.592465 -0.130136  0.300532  0.593418 -0.132346  0.263799  0.631488   \n",
       "54011  0.362683 -0.056083  0.594289  0.395130 -0.049286  0.582595  0.432643   \n",
       "14984  0.331391 -0.087306  0.365192  0.363674 -0.071107  0.334583  0.396168   \n",
       "15626  0.476533 -0.206874  0.305292  0.508867 -0.188753  0.240287  0.535760   \n",
       "54039  0.390176 -0.067134  0.664799  0.425318 -0.059622  0.647095  0.465285   \n",
       "\n",
       "            z21  \n",
       "12366 -0.131590  \n",
       "55885 -0.061398  \n",
       "2957  -0.115481  \n",
       "34102 -0.011252  \n",
       "21045  0.027799  \n",
       "...         ...  \n",
       "6466  -0.125428  \n",
       "54011 -0.038324  \n",
       "14984 -0.047291  \n",
       "15626 -0.155334  \n",
       "54039 -0.047364  \n",
       "\n",
       "[64042 rows x 63 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0abdd5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c3eedf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape input to the shape of your data\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7696997c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2949026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "801/801 [==============================] - 1s 498us/step - loss: 1.3021 - accuracy: 0.6956 - val_loss: 0.4671 - val_accuracy: 0.9009\n",
      "Epoch 2/20\n",
      "801/801 [==============================] - 0s 445us/step - loss: 0.3524 - accuracy: 0.9273 - val_loss: 0.2808 - val_accuracy: 0.9524\n",
      "Epoch 3/20\n",
      "801/801 [==============================] - 0s 443us/step - loss: 0.2449 - accuracy: 0.9503 - val_loss: 0.2226 - val_accuracy: 0.9569\n",
      "Epoch 4/20\n",
      "801/801 [==============================] - 0s 444us/step - loss: 0.1947 - accuracy: 0.9605 - val_loss: 0.1781 - val_accuracy: 0.9687\n",
      "Epoch 5/20\n",
      "801/801 [==============================] - 0s 444us/step - loss: 0.1615 - accuracy: 0.9669 - val_loss: 0.1617 - val_accuracy: 0.9644\n",
      "Epoch 6/20\n",
      "801/801 [==============================] - 0s 445us/step - loss: 0.1381 - accuracy: 0.9703 - val_loss: 0.1462 - val_accuracy: 0.9685\n",
      "Epoch 7/20\n",
      "801/801 [==============================] - 0s 443us/step - loss: 0.1250 - accuracy: 0.9733 - val_loss: 0.1178 - val_accuracy: 0.9767\n",
      "Epoch 8/20\n",
      "801/801 [==============================] - 0s 443us/step - loss: 0.1099 - accuracy: 0.9754 - val_loss: 0.1157 - val_accuracy: 0.9768\n",
      "Epoch 9/20\n",
      "801/801 [==============================] - 0s 443us/step - loss: 0.1001 - accuracy: 0.9778 - val_loss: 0.1061 - val_accuracy: 0.9768\n",
      "Epoch 10/20\n",
      "801/801 [==============================] - 0s 443us/step - loss: 0.0926 - accuracy: 0.9788 - val_loss: 0.1023 - val_accuracy: 0.9771\n",
      "Epoch 11/20\n",
      "801/801 [==============================] - 0s 443us/step - loss: 0.0843 - accuracy: 0.9804 - val_loss: 0.0880 - val_accuracy: 0.9810\n",
      "Epoch 12/20\n",
      "801/801 [==============================] - 0s 444us/step - loss: 0.0795 - accuracy: 0.9815 - val_loss: 0.0885 - val_accuracy: 0.9822\n",
      "Epoch 13/20\n",
      "801/801 [==============================] - 0s 443us/step - loss: 0.0741 - accuracy: 0.9824 - val_loss: 0.0880 - val_accuracy: 0.9810\n",
      "Epoch 14/20\n",
      "801/801 [==============================] - 0s 444us/step - loss: 0.0703 - accuracy: 0.9830 - val_loss: 0.0777 - val_accuracy: 0.9825\n",
      "Epoch 15/20\n",
      "801/801 [==============================] - 0s 442us/step - loss: 0.0656 - accuracy: 0.9840 - val_loss: 0.0701 - val_accuracy: 0.9824\n",
      "Epoch 16/20\n",
      "801/801 [==============================] - 0s 443us/step - loss: 0.0616 - accuracy: 0.9852 - val_loss: 0.0768 - val_accuracy: 0.9828\n",
      "Epoch 17/20\n",
      "801/801 [==============================] - 0s 452us/step - loss: 0.0604 - accuracy: 0.9847 - val_loss: 0.0676 - val_accuracy: 0.9843\n",
      "Epoch 18/20\n",
      "801/801 [==============================] - 0s 444us/step - loss: 0.0585 - accuracy: 0.9851 - val_loss: 0.0664 - val_accuracy: 0.9863\n",
      "Epoch 19/20\n",
      "801/801 [==============================] - 0s 443us/step - loss: 0.0529 - accuracy: 0.9867 - val_loss: 0.0701 - val_accuracy: 0.9837\n",
      "Epoch 20/20\n",
      "801/801 [==============================] - 0s 444us/step - loss: 0.0517 - accuracy: 0.9871 - val_loss: 0.0711 - val_accuracy: 0.9831\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model_cnn = Sequential()\n",
    "#model_cnn.add(Flatten(input_shape=input_shape))\n",
    "model_cnn.add(Dense(128, input_shape=(63,), activation='relu'))\n",
    "model_cnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_cnn.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "282b3666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 245us/step - loss: 0.0711 - accuracy: 0.9831\n",
      "Test Accuracy: 98.31%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy_cnn = model_cnn.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy_cnn*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a7c9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA to reduce dimensionality\n",
    "#pca = PCA(n_components=63)  # Maximum possible components\n",
    "#X_train_pca = pca.fit_transform(X_train)\n",
    "#X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Define new dimensions for the CNN-LSTM input\n",
    "num_time_steps = 7  # Adjust this based on your requirements\n",
    "height, width = 3, 3  # New dimensions that multiply to <= 63\n",
    "channels = 1  # Grayscale\n",
    "\n",
    "x_train_sl = scaler.fit_transform(X_train)\n",
    "x_test_sl = scaler.fit_transform(X_test)\n",
    "\n",
    "# Reshape data for CNN-LSTM input\n",
    "#X_train_pca = X_train_pca.reshape(-1, num_time_steps, height, width, channels)\n",
    "#X_test_pca = X_test_pca.reshape(-1, num_time_steps, height, width, channels)\n",
    "\n",
    "\n",
    "X_train_pca = x_train_sl.reshape(-1, num_time_steps, height, width, channels)\n",
    "X_test_pca = x_test_sl.reshape(-1, num_time_steps, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9fd504f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "801/801 [==============================] - 4s 4ms/step - loss: 2.2874 - accuracy: 0.2885 - val_loss: 1.3601 - val_accuracy: 0.5294\n",
      "Epoch 2/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 1.0291 - accuracy: 0.6668 - val_loss: 0.7855 - val_accuracy: 0.7579\n",
      "Epoch 3/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.6446 - accuracy: 0.8039 - val_loss: 0.6191 - val_accuracy: 0.7996\n",
      "Epoch 4/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.4550 - accuracy: 0.8622 - val_loss: 0.3963 - val_accuracy: 0.8765\n",
      "Epoch 5/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.3689 - accuracy: 0.8899 - val_loss: 0.3254 - val_accuracy: 0.9038\n",
      "Epoch 6/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.3104 - accuracy: 0.9063 - val_loss: 0.3109 - val_accuracy: 0.9037\n",
      "Epoch 7/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.2654 - accuracy: 0.9202 - val_loss: 0.2389 - val_accuracy: 0.9300\n",
      "Epoch 8/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.2342 - accuracy: 0.9295 - val_loss: 0.1898 - val_accuracy: 0.9480\n",
      "Epoch 9/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.2049 - accuracy: 0.9402 - val_loss: 0.2193 - val_accuracy: 0.9345\n",
      "Epoch 10/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.1835 - accuracy: 0.9470 - val_loss: 0.1905 - val_accuracy: 0.9403\n",
      "Epoch 11/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.1626 - accuracy: 0.9542 - val_loss: 0.1613 - val_accuracy: 0.9538\n",
      "Epoch 12/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.1443 - accuracy: 0.9597 - val_loss: 0.1259 - val_accuracy: 0.9656\n",
      "Epoch 13/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.1337 - accuracy: 0.9623 - val_loss: 0.1306 - val_accuracy: 0.9616\n",
      "Epoch 14/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.1232 - accuracy: 0.9656 - val_loss: 0.1181 - val_accuracy: 0.9696\n",
      "Epoch 15/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.1167 - accuracy: 0.9682 - val_loss: 0.1204 - val_accuracy: 0.9669\n",
      "Epoch 16/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.1014 - accuracy: 0.9720 - val_loss: 0.0981 - val_accuracy: 0.9755\n",
      "Epoch 17/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.0994 - accuracy: 0.9720 - val_loss: 0.1141 - val_accuracy: 0.9692\n",
      "Epoch 18/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.0883 - accuracy: 0.9754 - val_loss: 0.1055 - val_accuracy: 0.9703\n",
      "Epoch 19/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.0839 - accuracy: 0.9769 - val_loss: 0.0790 - val_accuracy: 0.9808\n",
      "Epoch 20/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.0790 - accuracy: 0.9780 - val_loss: 0.0912 - val_accuracy: 0.9756\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN-LSTM model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (2, 2), activation='relu'), input_shape=(num_time_steps, height, width, channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pca, y_train, epochs=20, batch_size=64, validation_data=(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e44181c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 764us/step - loss: 0.0912 - accuracy: 0.9756\n",
      "Test Accuracy: 97.56%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_pca, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f19100d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [class, x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5, x6, y6, z6, x7, y7, z7, x8, y8, z8, x9, y9, z9, x10, y10, z10, x11, y11, z11, x12, y12, z12, x13, y13, z13, x14, y14, z14, x15, y15, z15, x16, y16, z16, x17, y17, z17, x18, y18, z18, x19, y19, z19, x20, y20, z20, x21, y21, z21]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 64 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_pred_data = data.columns.values.tolist()\n",
    "pred_data = pd.DataFrame(columns = temp_pred_data)\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b74d8599",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "091b89ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "#scaler = StandardScaler()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "def coord(image):\n",
    "    try:\n",
    "        with mp_hands.Hands(\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5) as hands:\n",
    "            image = cv2.flip(image, 1)\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = hands.process(image)\n",
    "            if not results.multi_hand_landmarks:\n",
    "                pass\n",
    "            image_height, image_width, _ = image.shape\n",
    "            annotated_image = image.copy()\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                hands = results.multi_hand_landmarks[0].landmark\n",
    "                hand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in hands]).flatten())\n",
    "                #pred_data.loc[0] = hand_row\n",
    "                single_sample_scaled = scaler.transform([hand_row])  # The input must be 2D for the scaler\n",
    "\n",
    "                # Reshape the sample to add the batch and time step dimensions\n",
    "                single_sample_reshaped = single_sample_scaled.reshape(1, 21, 3)\n",
    "\n",
    "                \n",
    "                return single_sample_reshaped\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ec2379c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eda_cnn_lstm(cds):\n",
    "    # Perform PCA to reduce dimensionality\n",
    "    #pca = PCA(n_components=63)  # Maximum possible components\n",
    "    #cds_pca = pca.fit_transform(cds)\n",
    "\n",
    "    # Define new dimensions for the CNN-LSTM input\n",
    "    num_time_steps = 7  # Adjust this based on your requirements\n",
    "    height, width = 3, 3  # New dimensions that multiply to <= 63\n",
    "    channels = 1  # Grayscale\n",
    "\n",
    "    # Reshape data for CNN-LSTM input\n",
    "    cds_pca = cds.reshape(-1, num_time_steps, height, width, channels)\n",
    "    \n",
    "    return cds_pca\n",
    "\n",
    "\n",
    "def eda_cnn(cds):\n",
    "    cds_cnn = pre.reshape(1, -1) \n",
    "    return cds_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b50607f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample data for the graph\n",
    "accuracy_values = {\n",
    "    \"accuracy_cnn_lstm\": accuracy*100,       # Replace with actual accuracy value\n",
    "    \"accuracy_cnn\": accuracy_cnn*100,   # Replace with actual accuracy for CNN\n",
    "    \"accuracy_base\": accuracy_base*100   # Replace with actual baseline accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7244c518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(accuracy_values.keys(), accuracy_values.values(), color=['blue', 'green', 'red'])\n",
    "\n",
    "plt.xlabel('Model Type')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.ylim(0, 100)  # Set y-axis limit from 0 to 100\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993a176e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67fbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from collections import Counter\n",
    "cam = cv2.VideoCapture(0)\n",
    "previous = time()\n",
    "delta = 0\n",
    "s = ''\n",
    "\n",
    "while True:\n",
    "    # Get the current time, increase delta and update the previous variable\n",
    "    current = time()\n",
    "    delta += current - previous\n",
    "    previous = current\n",
    "    #t.sleep(30)\n",
    "    # Check if 3 (or some other value) seconds passed\n",
    "    if delta > 3:\n",
    "        # Operations on image\n",
    "        # Reset the time counter\n",
    "        delta = 0\n",
    "        # Show the image and keep streaming\n",
    "        _, img = cam.read()\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        cds = coord(img)\n",
    "        print(type(cds))\n",
    "        \n",
    "        cnn_lstm_flag = 0\n",
    "        cnn_flag = 0\n",
    "        base = 0\n",
    "        \n",
    "        try:\n",
    "            print(\"entering 1st try\")\n",
    "            #cds = cds.reshape(1,-1)\n",
    "            try:\n",
    "                #print(\"entering cnn lstm\")\n",
    "                cds_cnn_lstm = eda_cnn_lstm(cds)\n",
    "                cnn_lstm_prediction = model.predict(cds_cnn_lstm)\n",
    "                predicted_index_cnn_lstm = np.argmax(cnn_lstm_prediction, axis=1)[0]\n",
    "                cnn_lstm_flag = 1\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                #print(\"entering lstm try\")\n",
    "                base_prediction = model_Base.predict(cds)\n",
    "                predicted_index_base = np.argmax(base_prediction, axis=1)[0]\n",
    "                base_flag = 1\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                #print(\"entering cnn try\")\n",
    "                cds_cnn = eda_cnn(cds)\n",
    "                cnn_prediction = model_cnn.predict(cds_cnn)\n",
    "                predicted_index_cnn = np.argmax(cnn_prediction, axis=1)[0]\n",
    "                cnn_flag = 1\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            \n",
    "            '''if (cnn_lstm_flag == 1 and base_flag == 1 and cnn_flag == 1):\n",
    "                print(alphabets[predicted_index_base], alphabets[predicted_index_cnn], alphabets[predicted_index_cnn_lstm])\n",
    "            elif(cnn_lstm_flag == 0 and base_flag == 1 and cnn_flag == 1):\n",
    "                print(\"No cnn_lstm\")\n",
    "                print(alphabets[predicted_index_base], alphabets[predicted_index_cnn])\n",
    "            elif(cnn_lstm_flag == 1 and base_flag == 0 and cnn_flag == 1):\n",
    "                print(\"No base_flag\")\n",
    "                print(alphabets[predicted_index_cnn_lstm], alphabets[predicted_index_cnn])\n",
    "            elif(cnn_lstm_flag == 1 and base_flag == 1 and cnn_flag == 0):\n",
    "                print(\"No cnn\")\n",
    "                print(alphabets[predicted_index_base], alphabets[predicted_index_cnn_lstm])\n",
    "            else:\n",
    "                print(\"Only one model\")'''\n",
    "            \n",
    "            #print(predicted_index)\n",
    "            lst = [alphabets[predicted_index_base], alphabets[predicted_index_cnn], alphabets[predicted_index_cnn_lstm]]\n",
    "            #print(lst)\n",
    "            if len(lst) != len(set(lst)):\n",
    "                #print(\"entered if\")\n",
    "                duplicates = [item for item, count in Counter(lst).items() if count > 1]\n",
    "                print(duplicates[0])\n",
    "                s += duplicates[0]\n",
    "                if len(s) == 7:\n",
    "                    break\n",
    "            \n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "            \n",
    "        except:\n",
    "            pass\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ed3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
