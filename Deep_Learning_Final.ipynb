{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a68e981d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, TimeDistributed\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f617d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>0.530803</td>\n",
       "      <td>0.581163</td>\n",
       "      <td>-1.472346e-06</td>\n",
       "      <td>0.413990</td>\n",
       "      <td>0.501149</td>\n",
       "      <td>-0.018073</td>\n",
       "      <td>0.355407</td>\n",
       "      <td>0.369223</td>\n",
       "      <td>-0.029657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057639</td>\n",
       "      <td>0.605741</td>\n",
       "      <td>0.320499</td>\n",
       "      <td>-0.091212</td>\n",
       "      <td>0.588447</td>\n",
       "      <td>0.400885</td>\n",
       "      <td>-0.071050</td>\n",
       "      <td>0.594126</td>\n",
       "      <td>0.455363</td>\n",
       "      <td>-0.044118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A</td>\n",
       "      <td>0.503664</td>\n",
       "      <td>0.616673</td>\n",
       "      <td>-1.548741e-06</td>\n",
       "      <td>0.377512</td>\n",
       "      <td>0.536617</td>\n",
       "      <td>-0.016148</td>\n",
       "      <td>0.317852</td>\n",
       "      <td>0.408111</td>\n",
       "      <td>-0.028432</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057488</td>\n",
       "      <td>0.561715</td>\n",
       "      <td>0.359349</td>\n",
       "      <td>-0.085140</td>\n",
       "      <td>0.546541</td>\n",
       "      <td>0.440563</td>\n",
       "      <td>-0.067003</td>\n",
       "      <td>0.551058</td>\n",
       "      <td>0.498263</td>\n",
       "      <td>-0.044481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A</td>\n",
       "      <td>0.267808</td>\n",
       "      <td>0.670679</td>\n",
       "      <td>-8.506087e-07</td>\n",
       "      <td>0.187360</td>\n",
       "      <td>0.610215</td>\n",
       "      <td>-0.020350</td>\n",
       "      <td>0.141140</td>\n",
       "      <td>0.503103</td>\n",
       "      <td>-0.030225</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043488</td>\n",
       "      <td>0.369881</td>\n",
       "      <td>0.461587</td>\n",
       "      <td>-0.075160</td>\n",
       "      <td>0.362212</td>\n",
       "      <td>0.517269</td>\n",
       "      <td>-0.059621</td>\n",
       "      <td>0.349507</td>\n",
       "      <td>0.565708</td>\n",
       "      <td>-0.036153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>0.289091</td>\n",
       "      <td>0.751779</td>\n",
       "      <td>-1.795283e-06</td>\n",
       "      <td>0.167962</td>\n",
       "      <td>0.654705</td>\n",
       "      <td>-0.030267</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.499485</td>\n",
       "      <td>-0.048589</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059609</td>\n",
       "      <td>0.393687</td>\n",
       "      <td>0.455553</td>\n",
       "      <td>-0.107050</td>\n",
       "      <td>0.365366</td>\n",
       "      <td>0.547497</td>\n",
       "      <td>-0.087988</td>\n",
       "      <td>0.356335</td>\n",
       "      <td>0.612805</td>\n",
       "      <td>-0.058007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A</td>\n",
       "      <td>0.285160</td>\n",
       "      <td>0.762803</td>\n",
       "      <td>-1.769840e-06</td>\n",
       "      <td>0.161197</td>\n",
       "      <td>0.667723</td>\n",
       "      <td>-0.030836</td>\n",
       "      <td>0.094453</td>\n",
       "      <td>0.512100</td>\n",
       "      <td>-0.048447</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.059550</td>\n",
       "      <td>0.388296</td>\n",
       "      <td>0.466932</td>\n",
       "      <td>-0.105277</td>\n",
       "      <td>0.361084</td>\n",
       "      <td>0.560643</td>\n",
       "      <td>-0.085365</td>\n",
       "      <td>0.352804</td>\n",
       "      <td>0.623975</td>\n",
       "      <td>-0.055310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  class        x1        y1            z1        x2        y2        z2  \\\n",
       "0     A  0.530803  0.581163 -1.472346e-06  0.413990  0.501149 -0.018073   \n",
       "1     A  0.503664  0.616673 -1.548741e-06  0.377512  0.536617 -0.016148   \n",
       "2     A  0.267808  0.670679 -8.506087e-07  0.187360  0.610215 -0.020350   \n",
       "3     A  0.289091  0.751779 -1.795283e-06  0.167962  0.654705 -0.030267   \n",
       "4     A  0.285160  0.762803 -1.769840e-06  0.161197  0.667723 -0.030836   \n",
       "\n",
       "         x3        y3        z3  ...       z18       x19       y19       z19  \\\n",
       "0  0.355407  0.369223 -0.029657  ... -0.057639  0.605741  0.320499 -0.091212   \n",
       "1  0.317852  0.408111 -0.028432  ... -0.057488  0.561715  0.359349 -0.085140   \n",
       "2  0.141140  0.503103 -0.030225  ... -0.043488  0.369881  0.461587 -0.075160   \n",
       "3  0.100007  0.499485 -0.048589  ... -0.059609  0.393687  0.455553 -0.107050   \n",
       "4  0.094453  0.512100 -0.048447  ... -0.059550  0.388296  0.466932 -0.105277   \n",
       "\n",
       "        x20       y20       z20       x21       y21       z21  \n",
       "0  0.588447  0.400885 -0.071050  0.594126  0.455363 -0.044118  \n",
       "1  0.546541  0.440563 -0.067003  0.551058  0.498263 -0.044481  \n",
       "2  0.362212  0.517269 -0.059621  0.349507  0.565708 -0.036153  \n",
       "3  0.365366  0.547497 -0.087988  0.356335  0.612805 -0.058007  \n",
       "4  0.361084  0.560643 -0.085365  0.352804  0.623975 -0.055310  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"coords.csv\",index_col=False)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8986b64a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>A</td>\n",
       "      <td>0.761235</td>\n",
       "      <td>0.501182</td>\n",
       "      <td>-8.562953e-07</td>\n",
       "      <td>0.658610</td>\n",
       "      <td>0.456901</td>\n",
       "      <td>-0.030290</td>\n",
       "      <td>0.580043</td>\n",
       "      <td>0.368323</td>\n",
       "      <td>-0.044648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039038</td>\n",
       "      <td>0.828147</td>\n",
       "      <td>0.272384</td>\n",
       "      <td>-0.075885</td>\n",
       "      <td>0.824453</td>\n",
       "      <td>0.340032</td>\n",
       "      <td>-0.060200</td>\n",
       "      <td>0.818925</td>\n",
       "      <td>0.384807</td>\n",
       "      <td>-0.037907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28301</th>\n",
       "      <td>L</td>\n",
       "      <td>0.504249</td>\n",
       "      <td>0.539109</td>\n",
       "      <td>-1.206121e-07</td>\n",
       "      <td>0.403728</td>\n",
       "      <td>0.511307</td>\n",
       "      <td>-0.024695</td>\n",
       "      <td>0.323920</td>\n",
       "      <td>0.480352</td>\n",
       "      <td>-0.043604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026544</td>\n",
       "      <td>0.510099</td>\n",
       "      <td>0.325422</td>\n",
       "      <td>-0.048290</td>\n",
       "      <td>0.497715</td>\n",
       "      <td>0.376351</td>\n",
       "      <td>-0.030515</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.411247</td>\n",
       "      <td>-0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36522</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.652010</td>\n",
       "      <td>1.509529e-06</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>0.728496</td>\n",
       "      <td>-0.099155</td>\n",
       "      <td>0.138796</td>\n",
       "      <td>0.784399</td>\n",
       "      <td>-0.140557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.323063</td>\n",
       "      <td>0.572390</td>\n",
       "      <td>-0.028672</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.608054</td>\n",
       "      <td>-0.031056</td>\n",
       "      <td>0.288952</td>\n",
       "      <td>0.622333</td>\n",
       "      <td>-0.022249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53807</th>\n",
       "      <td>X</td>\n",
       "      <td>0.677257</td>\n",
       "      <td>0.896656</td>\n",
       "      <td>-3.083799e-08</td>\n",
       "      <td>0.625531</td>\n",
       "      <td>0.847047</td>\n",
       "      <td>-0.026996</td>\n",
       "      <td>0.603508</td>\n",
       "      <td>0.779853</td>\n",
       "      <td>-0.039130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045161</td>\n",
       "      <td>0.768227</td>\n",
       "      <td>0.738690</td>\n",
       "      <td>-0.073589</td>\n",
       "      <td>0.747754</td>\n",
       "      <td>0.775877</td>\n",
       "      <td>-0.065406</td>\n",
       "      <td>0.730394</td>\n",
       "      <td>0.807700</td>\n",
       "      <td>-0.051156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18117</th>\n",
       "      <td>H</td>\n",
       "      <td>0.308695</td>\n",
       "      <td>0.871564</td>\n",
       "      <td>1.159256e-06</td>\n",
       "      <td>0.278563</td>\n",
       "      <td>0.796059</td>\n",
       "      <td>-0.042845</td>\n",
       "      <td>0.326489</td>\n",
       "      <td>0.707279</td>\n",
       "      <td>-0.063556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071390</td>\n",
       "      <td>0.476656</td>\n",
       "      <td>0.799582</td>\n",
       "      <td>-0.125473</td>\n",
       "      <td>0.417410</td>\n",
       "      <td>0.810941</td>\n",
       "      <td>-0.122791</td>\n",
       "      <td>0.369383</td>\n",
       "      <td>0.825952</td>\n",
       "      <td>-0.106864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class        x1        y1            z1        x2        y2        z2  \\\n",
       "544       A  0.761235  0.501182 -8.562953e-07  0.658610  0.456901 -0.030290   \n",
       "28301     L  0.504249  0.539109 -1.206121e-07  0.403728  0.511307 -0.024695   \n",
       "36522     Q  0.025327  0.652010  1.509529e-06  0.059176  0.728496 -0.099155   \n",
       "53807     X  0.677257  0.896656 -3.083799e-08  0.625531  0.847047 -0.026996   \n",
       "18117     H  0.308695  0.871564  1.159256e-06  0.278563  0.796059 -0.042845   \n",
       "\n",
       "             x3        y3        z3  ...       z18       x19       y19  \\\n",
       "544    0.580043  0.368323 -0.044648  ... -0.039038  0.828147  0.272384   \n",
       "28301  0.323920  0.480352 -0.043604  ... -0.026544  0.510099  0.325422   \n",
       "36522  0.138796  0.784399 -0.140557  ...  0.000955  0.323063  0.572390   \n",
       "53807  0.603508  0.779853 -0.039130  ... -0.045161  0.768227  0.738690   \n",
       "18117  0.326489  0.707279 -0.063556  ... -0.071390  0.476656  0.799582   \n",
       "\n",
       "            z19       x20       y20       z20       x21       y21       z21  \n",
       "544   -0.075885  0.824453  0.340032 -0.060200  0.818925  0.384807 -0.037907  \n",
       "28301 -0.048290  0.497715  0.376351 -0.030515  0.501220  0.411247 -0.010667  \n",
       "36522 -0.028672  0.315457  0.608054 -0.031056  0.288952  0.622333 -0.022249  \n",
       "53807 -0.073589  0.747754  0.775877 -0.065406  0.730394  0.807700 -0.051156  \n",
       "18117 -0.125473  0.417410  0.810941 -0.122791  0.369383  0.825952 -0.106864  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.sample(frac=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a47123f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = dataset.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4259e29",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pauljohnmaddala/anaconda3/envs/tfenv/lib/python3.8/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the class labels\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "class_labels = dataset['class'].values.reshape(-1, 1)\n",
    "class_labels_encoded = encoder.fit_transform(class_labels)\n",
    "\n",
    "# Dropping the 'class' column from the dataset\n",
    "features = dataset.drop('class', axis=1)\n",
    "\n",
    "# Standardize the feature columns\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71521d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Since we don't have a time series, we will treat each coordinate set (x, y, z) as one time step.\n",
    "# This means we have 21 time steps with 3 features each.\n",
    "features_reshaped = features_scaled.reshape((features_scaled.shape[0], 21, 3))\n",
    "\n",
    "#features = features.to_numpy()\n",
    "\n",
    "#features_reshaped = features.reshape((features.shape[0], 21, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16940b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Splitting the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features_reshaped, class_labels_encoded, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2bef0938",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 01:05:48.382240: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 1.2115 - accuracy: 0.6273 - val_loss: 0.4339 - val_accuracy: 0.8663\n",
      "Epoch 2/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.3371 - accuracy: 0.8945 - val_loss: 0.3949 - val_accuracy: 0.8571\n",
      "Epoch 3/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9293 - val_loss: 0.2010 - val_accuracy: 0.9414\n",
      "Epoch 4/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.1787 - accuracy: 0.9462 - val_loss: 0.1843 - val_accuracy: 0.9439\n",
      "Epoch 5/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.1496 - accuracy: 0.9560 - val_loss: 0.1758 - val_accuracy: 0.9514\n",
      "Epoch 6/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.1255 - accuracy: 0.9631 - val_loss: 0.1215 - val_accuracy: 0.9650\n",
      "Epoch 7/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.1045 - accuracy: 0.9708 - val_loss: 0.1013 - val_accuracy: 0.9737\n",
      "Epoch 8/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0925 - accuracy: 0.9739 - val_loss: 0.0836 - val_accuracy: 0.9778\n",
      "Epoch 9/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0819 - accuracy: 0.9768 - val_loss: 0.0969 - val_accuracy: 0.9735\n",
      "Epoch 10/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0774 - accuracy: 0.9779 - val_loss: 0.0875 - val_accuracy: 0.9758\n",
      "Epoch 11/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0681 - accuracy: 0.9807 - val_loss: 0.0708 - val_accuracy: 0.9828\n",
      "Epoch 12/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0650 - accuracy: 0.9823 - val_loss: 0.0632 - val_accuracy: 0.9825\n",
      "Epoch 13/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0578 - accuracy: 0.9840 - val_loss: 0.0650 - val_accuracy: 0.9814\n",
      "Epoch 14/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0530 - accuracy: 0.9852 - val_loss: 0.0496 - val_accuracy: 0.9883\n",
      "Epoch 15/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0510 - accuracy: 0.9857 - val_loss: 0.0534 - val_accuracy: 0.9857\n",
      "Epoch 16/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0509 - accuracy: 0.9854 - val_loss: 0.0620 - val_accuracy: 0.9829\n",
      "Epoch 17/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0441 - accuracy: 0.9869 - val_loss: 0.0595 - val_accuracy: 0.9849\n",
      "Epoch 18/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0440 - accuracy: 0.9867 - val_loss: 0.0510 - val_accuracy: 0.9868\n",
      "Epoch 19/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0436 - accuracy: 0.9873 - val_loss: 0.0820 - val_accuracy: 0.9769\n",
      "Epoch 20/20\n",
      "1602/1602 [==============================] - 5s 3ms/step - loss: 0.0355 - accuracy: 0.9892 - val_loss: 0.0521 - val_accuracy: 0.9878\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x310dccaf0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the LSTM model\n",
    "model_Base = Sequential()\n",
    "model_Base.add(LSTM(50, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "model_Base.add(Dense(y_train.shape[1], activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_Base.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model_Base.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35ab31e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 98.78%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy_base = model_Base.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy: {accuracy_base*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9459227",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>A</td>\n",
       "      <td>0.761235</td>\n",
       "      <td>0.501182</td>\n",
       "      <td>-8.562953e-07</td>\n",
       "      <td>0.658610</td>\n",
       "      <td>0.456901</td>\n",
       "      <td>-0.030290</td>\n",
       "      <td>0.580043</td>\n",
       "      <td>0.368323</td>\n",
       "      <td>-0.044648</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039038</td>\n",
       "      <td>0.828147</td>\n",
       "      <td>0.272384</td>\n",
       "      <td>-0.075885</td>\n",
       "      <td>0.824453</td>\n",
       "      <td>0.340032</td>\n",
       "      <td>-0.060200</td>\n",
       "      <td>0.818925</td>\n",
       "      <td>0.384807</td>\n",
       "      <td>-0.037907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28301</th>\n",
       "      <td>L</td>\n",
       "      <td>0.504249</td>\n",
       "      <td>0.539109</td>\n",
       "      <td>-1.206121e-07</td>\n",
       "      <td>0.403728</td>\n",
       "      <td>0.511307</td>\n",
       "      <td>-0.024695</td>\n",
       "      <td>0.323920</td>\n",
       "      <td>0.480352</td>\n",
       "      <td>-0.043604</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026544</td>\n",
       "      <td>0.510099</td>\n",
       "      <td>0.325422</td>\n",
       "      <td>-0.048290</td>\n",
       "      <td>0.497715</td>\n",
       "      <td>0.376351</td>\n",
       "      <td>-0.030515</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.411247</td>\n",
       "      <td>-0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36522</th>\n",
       "      <td>Q</td>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.652010</td>\n",
       "      <td>1.509529e-06</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>0.728496</td>\n",
       "      <td>-0.099155</td>\n",
       "      <td>0.138796</td>\n",
       "      <td>0.784399</td>\n",
       "      <td>-0.140557</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.323063</td>\n",
       "      <td>0.572390</td>\n",
       "      <td>-0.028672</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.608054</td>\n",
       "      <td>-0.031056</td>\n",
       "      <td>0.288952</td>\n",
       "      <td>0.622333</td>\n",
       "      <td>-0.022249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53807</th>\n",
       "      <td>X</td>\n",
       "      <td>0.677257</td>\n",
       "      <td>0.896656</td>\n",
       "      <td>-3.083799e-08</td>\n",
       "      <td>0.625531</td>\n",
       "      <td>0.847047</td>\n",
       "      <td>-0.026996</td>\n",
       "      <td>0.603508</td>\n",
       "      <td>0.779853</td>\n",
       "      <td>-0.039130</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045161</td>\n",
       "      <td>0.768227</td>\n",
       "      <td>0.738690</td>\n",
       "      <td>-0.073589</td>\n",
       "      <td>0.747754</td>\n",
       "      <td>0.775877</td>\n",
       "      <td>-0.065406</td>\n",
       "      <td>0.730394</td>\n",
       "      <td>0.807700</td>\n",
       "      <td>-0.051156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18117</th>\n",
       "      <td>H</td>\n",
       "      <td>0.308695</td>\n",
       "      <td>0.871564</td>\n",
       "      <td>1.159256e-06</td>\n",
       "      <td>0.278563</td>\n",
       "      <td>0.796059</td>\n",
       "      <td>-0.042845</td>\n",
       "      <td>0.326489</td>\n",
       "      <td>0.707279</td>\n",
       "      <td>-0.063556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071390</td>\n",
       "      <td>0.476656</td>\n",
       "      <td>0.799582</td>\n",
       "      <td>-0.125473</td>\n",
       "      <td>0.417410</td>\n",
       "      <td>0.810941</td>\n",
       "      <td>-0.122791</td>\n",
       "      <td>0.369383</td>\n",
       "      <td>0.825952</td>\n",
       "      <td>-0.106864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50355</th>\n",
       "      <td>V</td>\n",
       "      <td>0.289232</td>\n",
       "      <td>0.915019</td>\n",
       "      <td>6.627998e-07</td>\n",
       "      <td>0.208964</td>\n",
       "      <td>0.843007</td>\n",
       "      <td>-0.026902</td>\n",
       "      <td>0.172380</td>\n",
       "      <td>0.745871</td>\n",
       "      <td>-0.039291</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055901</td>\n",
       "      <td>0.359594</td>\n",
       "      <td>0.676755</td>\n",
       "      <td>-0.086813</td>\n",
       "      <td>0.331411</td>\n",
       "      <td>0.715875</td>\n",
       "      <td>-0.076101</td>\n",
       "      <td>0.325787</td>\n",
       "      <td>0.760038</td>\n",
       "      <td>-0.057755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61236</th>\n",
       "      <td>del</td>\n",
       "      <td>0.664431</td>\n",
       "      <td>0.660977</td>\n",
       "      <td>6.841468e-07</td>\n",
       "      <td>0.716514</td>\n",
       "      <td>0.648983</td>\n",
       "      <td>-0.091384</td>\n",
       "      <td>0.817404</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>-0.114148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047910</td>\n",
       "      <td>0.929489</td>\n",
       "      <td>0.716655</td>\n",
       "      <td>0.018185</td>\n",
       "      <td>0.937645</td>\n",
       "      <td>0.762168</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>0.940391</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>-0.008166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16769</th>\n",
       "      <td>H</td>\n",
       "      <td>0.281167</td>\n",
       "      <td>0.729602</td>\n",
       "      <td>1.003158e-06</td>\n",
       "      <td>0.263632</td>\n",
       "      <td>0.650444</td>\n",
       "      <td>-0.026747</td>\n",
       "      <td>0.300768</td>\n",
       "      <td>0.570793</td>\n",
       "      <td>-0.041457</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063499</td>\n",
       "      <td>0.443942</td>\n",
       "      <td>0.637128</td>\n",
       "      <td>-0.099133</td>\n",
       "      <td>0.399651</td>\n",
       "      <td>0.644715</td>\n",
       "      <td>-0.094932</td>\n",
       "      <td>0.360351</td>\n",
       "      <td>0.663374</td>\n",
       "      <td>-0.082302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14326</th>\n",
       "      <td>G</td>\n",
       "      <td>0.528400</td>\n",
       "      <td>0.756823</td>\n",
       "      <td>-1.646316e-07</td>\n",
       "      <td>0.473261</td>\n",
       "      <td>0.675203</td>\n",
       "      <td>-0.049730</td>\n",
       "      <td>0.496130</td>\n",
       "      <td>0.548969</td>\n",
       "      <td>-0.073882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082827</td>\n",
       "      <td>0.766898</td>\n",
       "      <td>0.699161</td>\n",
       "      <td>-0.135965</td>\n",
       "      <td>0.697661</td>\n",
       "      <td>0.729025</td>\n",
       "      <td>-0.112129</td>\n",
       "      <td>0.651824</td>\n",
       "      <td>0.751734</td>\n",
       "      <td>-0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17627</th>\n",
       "      <td>H</td>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.604116</td>\n",
       "      <td>-1.270779e-06</td>\n",
       "      <td>0.088305</td>\n",
       "      <td>0.519366</td>\n",
       "      <td>-0.061572</td>\n",
       "      <td>0.165905</td>\n",
       "      <td>0.402005</td>\n",
       "      <td>-0.145346</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230664</td>\n",
       "      <td>0.314327</td>\n",
       "      <td>0.457134</td>\n",
       "      <td>-0.273344</td>\n",
       "      <td>0.334047</td>\n",
       "      <td>0.456876</td>\n",
       "      <td>-0.252677</td>\n",
       "      <td>0.314799</td>\n",
       "      <td>0.469201</td>\n",
       "      <td>-0.239413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64042 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      class        x1        y1            z1        x2        y2        z2  \\\n",
       "544       A  0.761235  0.501182 -8.562953e-07  0.658610  0.456901 -0.030290   \n",
       "28301     L  0.504249  0.539109 -1.206121e-07  0.403728  0.511307 -0.024695   \n",
       "36522     Q  0.025327  0.652010  1.509529e-06  0.059176  0.728496 -0.099155   \n",
       "53807     X  0.677257  0.896656 -3.083799e-08  0.625531  0.847047 -0.026996   \n",
       "18117     H  0.308695  0.871564  1.159256e-06  0.278563  0.796059 -0.042845   \n",
       "...     ...       ...       ...           ...       ...       ...       ...   \n",
       "50355     V  0.289232  0.915019  6.627998e-07  0.208964  0.843007 -0.026902   \n",
       "61236   del  0.664431  0.660977  6.841468e-07  0.716514  0.648983 -0.091384   \n",
       "16769     H  0.281167  0.729602  1.003158e-06  0.263632  0.650444 -0.026747   \n",
       "14326     G  0.528400  0.756823 -1.646316e-07  0.473261  0.675203 -0.049730   \n",
       "17627     H  0.080780  0.604116 -1.270779e-06  0.088305  0.519366 -0.061572   \n",
       "\n",
       "             x3        y3        z3  ...       z18       x19       y19  \\\n",
       "544    0.580043  0.368323 -0.044648  ... -0.039038  0.828147  0.272384   \n",
       "28301  0.323920  0.480352 -0.043604  ... -0.026544  0.510099  0.325422   \n",
       "36522  0.138796  0.784399 -0.140557  ...  0.000955  0.323063  0.572390   \n",
       "53807  0.603508  0.779853 -0.039130  ... -0.045161  0.768227  0.738690   \n",
       "18117  0.326489  0.707279 -0.063556  ... -0.071390  0.476656  0.799582   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "50355  0.172380  0.745871 -0.039291  ... -0.055901  0.359594  0.676755   \n",
       "61236  0.817404  0.635938 -0.114148  ...  0.047910  0.929489  0.716655   \n",
       "16769  0.300768  0.570793 -0.041457  ... -0.063499  0.443942  0.637128   \n",
       "14326  0.496130  0.548969 -0.073882  ... -0.082827  0.766898  0.699161   \n",
       "17627  0.165905  0.402005 -0.145346  ... -0.230664  0.314327  0.457134   \n",
       "\n",
       "            z19       x20       y20       z20       x21       y21       z21  \n",
       "544   -0.075885  0.824453  0.340032 -0.060200  0.818925  0.384807 -0.037907  \n",
       "28301 -0.048290  0.497715  0.376351 -0.030515  0.501220  0.411247 -0.010667  \n",
       "36522 -0.028672  0.315457  0.608054 -0.031056  0.288952  0.622333 -0.022249  \n",
       "53807 -0.073589  0.747754  0.775877 -0.065406  0.730394  0.807700 -0.051156  \n",
       "18117 -0.125473  0.417410  0.810941 -0.122791  0.369383  0.825952 -0.106864  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "50355 -0.086813  0.331411  0.715875 -0.076101  0.325787  0.760038 -0.057755  \n",
       "61236  0.018185  0.937645  0.762168 -0.000492  0.940391  0.801785 -0.008166  \n",
       "16769 -0.099133  0.399651  0.644715 -0.094932  0.360351  0.663374 -0.082302  \n",
       "14326 -0.135965  0.697661  0.729025 -0.112129  0.651824  0.751734 -0.079237  \n",
       "17627 -0.273344  0.334047  0.456876 -0.252677  0.314799  0.469201 -0.239413  \n",
       "\n",
       "[64042 rows x 64 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5ac0b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n",
    "\n",
    "# Encoding the class labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dc5c7d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>x4</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>0.761235</td>\n",
       "      <td>0.501182</td>\n",
       "      <td>-8.562953e-07</td>\n",
       "      <td>0.658610</td>\n",
       "      <td>0.456901</td>\n",
       "      <td>-0.030290</td>\n",
       "      <td>0.580043</td>\n",
       "      <td>0.368323</td>\n",
       "      <td>-0.044648</td>\n",
       "      <td>0.559197</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.039038</td>\n",
       "      <td>0.828147</td>\n",
       "      <td>0.272384</td>\n",
       "      <td>-0.075885</td>\n",
       "      <td>0.824453</td>\n",
       "      <td>0.340032</td>\n",
       "      <td>-0.060200</td>\n",
       "      <td>0.818925</td>\n",
       "      <td>0.384807</td>\n",
       "      <td>-0.037907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28301</th>\n",
       "      <td>0.504249</td>\n",
       "      <td>0.539109</td>\n",
       "      <td>-1.206121e-07</td>\n",
       "      <td>0.403728</td>\n",
       "      <td>0.511307</td>\n",
       "      <td>-0.024695</td>\n",
       "      <td>0.323920</td>\n",
       "      <td>0.480352</td>\n",
       "      <td>-0.043604</td>\n",
       "      <td>0.250590</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026544</td>\n",
       "      <td>0.510099</td>\n",
       "      <td>0.325422</td>\n",
       "      <td>-0.048290</td>\n",
       "      <td>0.497715</td>\n",
       "      <td>0.376351</td>\n",
       "      <td>-0.030515</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.411247</td>\n",
       "      <td>-0.010667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36522</th>\n",
       "      <td>0.025327</td>\n",
       "      <td>0.652010</td>\n",
       "      <td>1.509529e-06</td>\n",
       "      <td>0.059176</td>\n",
       "      <td>0.728496</td>\n",
       "      <td>-0.099155</td>\n",
       "      <td>0.138796</td>\n",
       "      <td>0.784399</td>\n",
       "      <td>-0.140557</td>\n",
       "      <td>0.214809</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000955</td>\n",
       "      <td>0.323063</td>\n",
       "      <td>0.572390</td>\n",
       "      <td>-0.028672</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.608054</td>\n",
       "      <td>-0.031056</td>\n",
       "      <td>0.288952</td>\n",
       "      <td>0.622333</td>\n",
       "      <td>-0.022249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53807</th>\n",
       "      <td>0.677257</td>\n",
       "      <td>0.896656</td>\n",
       "      <td>-3.083799e-08</td>\n",
       "      <td>0.625531</td>\n",
       "      <td>0.847047</td>\n",
       "      <td>-0.026996</td>\n",
       "      <td>0.603508</td>\n",
       "      <td>0.779853</td>\n",
       "      <td>-0.039130</td>\n",
       "      <td>0.651163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045161</td>\n",
       "      <td>0.768227</td>\n",
       "      <td>0.738690</td>\n",
       "      <td>-0.073589</td>\n",
       "      <td>0.747754</td>\n",
       "      <td>0.775877</td>\n",
       "      <td>-0.065406</td>\n",
       "      <td>0.730394</td>\n",
       "      <td>0.807700</td>\n",
       "      <td>-0.051156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18117</th>\n",
       "      <td>0.308695</td>\n",
       "      <td>0.871564</td>\n",
       "      <td>1.159256e-06</td>\n",
       "      <td>0.278563</td>\n",
       "      <td>0.796059</td>\n",
       "      <td>-0.042845</td>\n",
       "      <td>0.326489</td>\n",
       "      <td>0.707279</td>\n",
       "      <td>-0.063556</td>\n",
       "      <td>0.421233</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.071390</td>\n",
       "      <td>0.476656</td>\n",
       "      <td>0.799582</td>\n",
       "      <td>-0.125473</td>\n",
       "      <td>0.417410</td>\n",
       "      <td>0.810941</td>\n",
       "      <td>-0.122791</td>\n",
       "      <td>0.369383</td>\n",
       "      <td>0.825952</td>\n",
       "      <td>-0.106864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50355</th>\n",
       "      <td>0.289232</td>\n",
       "      <td>0.915019</td>\n",
       "      <td>6.627998e-07</td>\n",
       "      <td>0.208964</td>\n",
       "      <td>0.843007</td>\n",
       "      <td>-0.026902</td>\n",
       "      <td>0.172380</td>\n",
       "      <td>0.745871</td>\n",
       "      <td>-0.039291</td>\n",
       "      <td>0.226041</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.055901</td>\n",
       "      <td>0.359594</td>\n",
       "      <td>0.676755</td>\n",
       "      <td>-0.086813</td>\n",
       "      <td>0.331411</td>\n",
       "      <td>0.715875</td>\n",
       "      <td>-0.076101</td>\n",
       "      <td>0.325787</td>\n",
       "      <td>0.760038</td>\n",
       "      <td>-0.057755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61236</th>\n",
       "      <td>0.664431</td>\n",
       "      <td>0.660977</td>\n",
       "      <td>6.841468e-07</td>\n",
       "      <td>0.716514</td>\n",
       "      <td>0.648983</td>\n",
       "      <td>-0.091384</td>\n",
       "      <td>0.817404</td>\n",
       "      <td>0.635938</td>\n",
       "      <td>-0.114148</td>\n",
       "      <td>0.902418</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047910</td>\n",
       "      <td>0.929489</td>\n",
       "      <td>0.716655</td>\n",
       "      <td>0.018185</td>\n",
       "      <td>0.937645</td>\n",
       "      <td>0.762168</td>\n",
       "      <td>-0.000492</td>\n",
       "      <td>0.940391</td>\n",
       "      <td>0.801785</td>\n",
       "      <td>-0.008166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16769</th>\n",
       "      <td>0.281167</td>\n",
       "      <td>0.729602</td>\n",
       "      <td>1.003158e-06</td>\n",
       "      <td>0.263632</td>\n",
       "      <td>0.650444</td>\n",
       "      <td>-0.026747</td>\n",
       "      <td>0.300768</td>\n",
       "      <td>0.570793</td>\n",
       "      <td>-0.041457</td>\n",
       "      <td>0.377543</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.063499</td>\n",
       "      <td>0.443942</td>\n",
       "      <td>0.637128</td>\n",
       "      <td>-0.099133</td>\n",
       "      <td>0.399651</td>\n",
       "      <td>0.644715</td>\n",
       "      <td>-0.094932</td>\n",
       "      <td>0.360351</td>\n",
       "      <td>0.663374</td>\n",
       "      <td>-0.082302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14326</th>\n",
       "      <td>0.528400</td>\n",
       "      <td>0.756823</td>\n",
       "      <td>-1.646316e-07</td>\n",
       "      <td>0.473261</td>\n",
       "      <td>0.675203</td>\n",
       "      <td>-0.049730</td>\n",
       "      <td>0.496130</td>\n",
       "      <td>0.548969</td>\n",
       "      <td>-0.073882</td>\n",
       "      <td>0.563165</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.082827</td>\n",
       "      <td>0.766898</td>\n",
       "      <td>0.699161</td>\n",
       "      <td>-0.135965</td>\n",
       "      <td>0.697661</td>\n",
       "      <td>0.729025</td>\n",
       "      <td>-0.112129</td>\n",
       "      <td>0.651824</td>\n",
       "      <td>0.751734</td>\n",
       "      <td>-0.079237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17627</th>\n",
       "      <td>0.080780</td>\n",
       "      <td>0.604116</td>\n",
       "      <td>-1.270779e-06</td>\n",
       "      <td>0.088305</td>\n",
       "      <td>0.519366</td>\n",
       "      <td>-0.061572</td>\n",
       "      <td>0.165905</td>\n",
       "      <td>0.402005</td>\n",
       "      <td>-0.145346</td>\n",
       "      <td>0.274932</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.230664</td>\n",
       "      <td>0.314327</td>\n",
       "      <td>0.457134</td>\n",
       "      <td>-0.273344</td>\n",
       "      <td>0.334047</td>\n",
       "      <td>0.456876</td>\n",
       "      <td>-0.252677</td>\n",
       "      <td>0.314799</td>\n",
       "      <td>0.469201</td>\n",
       "      <td>-0.239413</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64042 rows Ã— 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             x1        y1            z1        x2        y2        z2  \\\n",
       "544    0.761235  0.501182 -8.562953e-07  0.658610  0.456901 -0.030290   \n",
       "28301  0.504249  0.539109 -1.206121e-07  0.403728  0.511307 -0.024695   \n",
       "36522  0.025327  0.652010  1.509529e-06  0.059176  0.728496 -0.099155   \n",
       "53807  0.677257  0.896656 -3.083799e-08  0.625531  0.847047 -0.026996   \n",
       "18117  0.308695  0.871564  1.159256e-06  0.278563  0.796059 -0.042845   \n",
       "...         ...       ...           ...       ...       ...       ...   \n",
       "50355  0.289232  0.915019  6.627998e-07  0.208964  0.843007 -0.026902   \n",
       "61236  0.664431  0.660977  6.841468e-07  0.716514  0.648983 -0.091384   \n",
       "16769  0.281167  0.729602  1.003158e-06  0.263632  0.650444 -0.026747   \n",
       "14326  0.528400  0.756823 -1.646316e-07  0.473261  0.675203 -0.049730   \n",
       "17627  0.080780  0.604116 -1.270779e-06  0.088305  0.519366 -0.061572   \n",
       "\n",
       "             x3        y3        z3        x4  ...       z18       x19  \\\n",
       "544    0.580043  0.368323 -0.044648  0.559197  ... -0.039038  0.828147   \n",
       "28301  0.323920  0.480352 -0.043604  0.250590  ... -0.026544  0.510099   \n",
       "36522  0.138796  0.784399 -0.140557  0.214809  ...  0.000955  0.323063   \n",
       "53807  0.603508  0.779853 -0.039130  0.651163  ... -0.045161  0.768227   \n",
       "18117  0.326489  0.707279 -0.063556  0.421233  ... -0.071390  0.476656   \n",
       "...         ...       ...       ...       ...  ...       ...       ...   \n",
       "50355  0.172380  0.745871 -0.039291  0.226041  ... -0.055901  0.359594   \n",
       "61236  0.817404  0.635938 -0.114148  0.902418  ...  0.047910  0.929489   \n",
       "16769  0.300768  0.570793 -0.041457  0.377543  ... -0.063499  0.443942   \n",
       "14326  0.496130  0.548969 -0.073882  0.563165  ... -0.082827  0.766898   \n",
       "17627  0.165905  0.402005 -0.145346  0.274932  ... -0.230664  0.314327   \n",
       "\n",
       "            y19       z19       x20       y20       z20       x21       y21  \\\n",
       "544    0.272384 -0.075885  0.824453  0.340032 -0.060200  0.818925  0.384807   \n",
       "28301  0.325422 -0.048290  0.497715  0.376351 -0.030515  0.501220  0.411247   \n",
       "36522  0.572390 -0.028672  0.315457  0.608054 -0.031056  0.288952  0.622333   \n",
       "53807  0.738690 -0.073589  0.747754  0.775877 -0.065406  0.730394  0.807700   \n",
       "18117  0.799582 -0.125473  0.417410  0.810941 -0.122791  0.369383  0.825952   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "50355  0.676755 -0.086813  0.331411  0.715875 -0.076101  0.325787  0.760038   \n",
       "61236  0.716655  0.018185  0.937645  0.762168 -0.000492  0.940391  0.801785   \n",
       "16769  0.637128 -0.099133  0.399651  0.644715 -0.094932  0.360351  0.663374   \n",
       "14326  0.699161 -0.135965  0.697661  0.729025 -0.112129  0.651824  0.751734   \n",
       "17627  0.457134 -0.273344  0.334047  0.456876 -0.252677  0.314799  0.469201   \n",
       "\n",
       "            z21  \n",
       "544   -0.037907  \n",
       "28301 -0.010667  \n",
       "36522 -0.022249  \n",
       "53807 -0.051156  \n",
       "18117 -0.106864  \n",
       "...         ...  \n",
       "50355 -0.057755  \n",
       "61236 -0.008166  \n",
       "16769 -0.082302  \n",
       "14326 -0.079237  \n",
       "17627 -0.239413  \n",
       "\n",
       "[64042 rows x 63 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0abdd5c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert DataFrame to NumPy array\n",
    "X_train = X_train.to_numpy()\n",
    "X_test = X_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c3eedf1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reshape input to the shape of your data\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7696997c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2949026",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "801/801 [==============================] - 1s 501us/step - loss: 1.3160 - accuracy: 0.6834 - val_loss: 0.4889 - val_accuracy: 0.8952\n",
      "Epoch 2/20\n",
      "801/801 [==============================] - 0s 475us/step - loss: 0.3909 - accuracy: 0.9105 - val_loss: 0.3050 - val_accuracy: 0.9296\n",
      "Epoch 3/20\n",
      "801/801 [==============================] - 0s 451us/step - loss: 0.2703 - accuracy: 0.9425 - val_loss: 0.2233 - val_accuracy: 0.9522\n",
      "Epoch 4/20\n",
      "801/801 [==============================] - 0s 448us/step - loss: 0.2100 - accuracy: 0.9569 - val_loss: 0.1800 - val_accuracy: 0.9657\n",
      "Epoch 5/20\n",
      "801/801 [==============================] - 0s 457us/step - loss: 0.1720 - accuracy: 0.9650 - val_loss: 0.1458 - val_accuracy: 0.9678\n",
      "Epoch 6/20\n",
      "801/801 [==============================] - 0s 453us/step - loss: 0.1500 - accuracy: 0.9676 - val_loss: 0.1337 - val_accuracy: 0.9718\n",
      "Epoch 7/20\n",
      "801/801 [==============================] - 0s 452us/step - loss: 0.1353 - accuracy: 0.9690 - val_loss: 0.1172 - val_accuracy: 0.9746\n",
      "Epoch 8/20\n",
      "801/801 [==============================] - 0s 451us/step - loss: 0.1191 - accuracy: 0.9737 - val_loss: 0.1221 - val_accuracy: 0.9716\n",
      "Epoch 9/20\n",
      "801/801 [==============================] - 0s 449us/step - loss: 0.1089 - accuracy: 0.9758 - val_loss: 0.1045 - val_accuracy: 0.9776\n",
      "Epoch 10/20\n",
      "801/801 [==============================] - 0s 448us/step - loss: 0.1001 - accuracy: 0.9780 - val_loss: 0.0947 - val_accuracy: 0.9783\n",
      "Epoch 11/20\n",
      "801/801 [==============================] - 0s 451us/step - loss: 0.0928 - accuracy: 0.9782 - val_loss: 0.0951 - val_accuracy: 0.9777\n",
      "Epoch 12/20\n",
      "801/801 [==============================] - 0s 449us/step - loss: 0.0859 - accuracy: 0.9791 - val_loss: 0.1114 - val_accuracy: 0.9705\n",
      "Epoch 13/20\n",
      "801/801 [==============================] - 0s 448us/step - loss: 0.0828 - accuracy: 0.9798 - val_loss: 0.0811 - val_accuracy: 0.9812\n",
      "Epoch 14/20\n",
      "801/801 [==============================] - 0s 461us/step - loss: 0.0760 - accuracy: 0.9818 - val_loss: 0.0712 - val_accuracy: 0.9818\n",
      "Epoch 15/20\n",
      "801/801 [==============================] - 0s 452us/step - loss: 0.0725 - accuracy: 0.9825 - val_loss: 0.0726 - val_accuracy: 0.9828\n",
      "Epoch 16/20\n",
      "801/801 [==============================] - 0s 470us/step - loss: 0.0669 - accuracy: 0.9837 - val_loss: 0.0725 - val_accuracy: 0.9827\n",
      "Epoch 17/20\n",
      "801/801 [==============================] - 0s 484us/step - loss: 0.0646 - accuracy: 0.9843 - val_loss: 0.0657 - val_accuracy: 0.9843\n",
      "Epoch 18/20\n",
      "801/801 [==============================] - 0s 492us/step - loss: 0.0638 - accuracy: 0.9844 - val_loss: 0.0614 - val_accuracy: 0.9854\n",
      "Epoch 19/20\n",
      "801/801 [==============================] - 0s 460us/step - loss: 0.0582 - accuracy: 0.9853 - val_loss: 0.0597 - val_accuracy: 0.9855\n",
      "Epoch 20/20\n",
      "801/801 [==============================] - 0s 448us/step - loss: 0.0574 - accuracy: 0.9853 - val_loss: 0.0554 - val_accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN model\n",
    "model_cnn = Sequential()\n",
    "#model_cnn.add(Flatten(input_shape=input_shape))\n",
    "model_cnn.add(Dense(128, input_shape=(63,), activation='relu'))\n",
    "model_cnn.add(Dense(64, activation='relu'))\n",
    "model_cnn.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model_cnn.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model_cnn.fit(X_train, y_train, epochs=20, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "282b3666",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 250us/step - loss: 0.0554 - accuracy: 0.9854\n",
      "Test Accuracy: 98.54%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy_cnn = model_cnn.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy_cnn*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a7c9e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Perform PCA to reduce dimensionality\n",
    "#pca = PCA(n_components=63)  # Maximum possible components\n",
    "#X_train_pca = pca.fit_transform(X_train)\n",
    "#X_test_pca = pca.transform(X_test)\n",
    "\n",
    "# Define new dimensions for the CNN-LSTM input\n",
    "num_time_steps = 7  # Adjust this based on your requirements\n",
    "height, width = 3, 3  # New dimensions that multiply to <= 63\n",
    "channels = 1  # Grayscale\n",
    "\n",
    "x_train_sl = scaler.fit_transform(X_train)\n",
    "x_test_sl = scaler.fit_transform(X_test)\n",
    "\n",
    "# Reshape data for CNN-LSTM input\n",
    "#X_train_pca = X_train_pca.reshape(-1, num_time_steps, height, width, channels)\n",
    "#X_test_pca = X_test_pca.reshape(-1, num_time_steps, height, width, channels)\n",
    "\n",
    "\n",
    "X_train_pca = x_train_sl.reshape(-1, num_time_steps, height, width, channels)\n",
    "X_test_pca = x_test_sl.reshape(-1, num_time_steps, height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9fd504f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "801/801 [==============================] - 4s 4ms/step - loss: 2.2979 - accuracy: 0.2819 - val_loss: 1.4840 - val_accuracy: 0.5019\n",
      "Epoch 2/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 1.1560 - accuracy: 0.6102 - val_loss: 0.9086 - val_accuracy: 0.6914\n",
      "Epoch 3/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.7653 - accuracy: 0.7517 - val_loss: 0.6578 - val_accuracy: 0.7942\n",
      "Epoch 4/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.5549 - accuracy: 0.8347 - val_loss: 0.4740 - val_accuracy: 0.8631\n",
      "Epoch 5/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.4305 - accuracy: 0.8725 - val_loss: 0.3503 - val_accuracy: 0.8980\n",
      "Epoch 6/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.3443 - accuracy: 0.8983 - val_loss: 0.3193 - val_accuracy: 0.9055\n",
      "Epoch 7/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.2882 - accuracy: 0.9132 - val_loss: 0.2598 - val_accuracy: 0.9208\n",
      "Epoch 8/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.2522 - accuracy: 0.9245 - val_loss: 0.2293 - val_accuracy: 0.9327\n",
      "Epoch 9/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.2254 - accuracy: 0.9330 - val_loss: 0.1998 - val_accuracy: 0.9429\n",
      "Epoch 10/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.2024 - accuracy: 0.9406 - val_loss: 0.2060 - val_accuracy: 0.9396\n",
      "Epoch 11/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.1816 - accuracy: 0.9470 - val_loss: 0.1813 - val_accuracy: 0.9460\n",
      "Epoch 12/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.1648 - accuracy: 0.9518 - val_loss: 0.1800 - val_accuracy: 0.9508\n",
      "Epoch 13/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.1535 - accuracy: 0.9569 - val_loss: 0.1519 - val_accuracy: 0.9560\n",
      "Epoch 14/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.1382 - accuracy: 0.9607 - val_loss: 0.1294 - val_accuracy: 0.9664\n",
      "Epoch 15/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.1311 - accuracy: 0.9628 - val_loss: 0.1357 - val_accuracy: 0.9628\n",
      "Epoch 16/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.1163 - accuracy: 0.9677 - val_loss: 0.1406 - val_accuracy: 0.9603\n",
      "Epoch 17/20\n",
      "801/801 [==============================] - 3s 3ms/step - loss: 0.1110 - accuracy: 0.9692 - val_loss: 0.1121 - val_accuracy: 0.9687\n",
      "Epoch 18/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.1019 - accuracy: 0.9712 - val_loss: 0.1197 - val_accuracy: 0.9679\n",
      "Epoch 19/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.0932 - accuracy: 0.9736 - val_loss: 0.1131 - val_accuracy: 0.9689\n",
      "Epoch 20/20\n",
      "801/801 [==============================] - 3s 4ms/step - loss: 0.0919 - accuracy: 0.9747 - val_loss: 0.1358 - val_accuracy: 0.9629\n"
     ]
    }
   ],
   "source": [
    "# Define the CNN-LSTM model\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (2, 2), activation='relu'), input_shape=(num_time_steps, height, width, channels)))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(LSTM(50, return_sequences=True))\n",
    "model.add(LSTM(20))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_pca, y_train, epochs=20, batch_size=64, validation_data=(X_test_pca, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e44181c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "401/401 [==============================] - 0s 772us/step - loss: 0.1358 - accuracy: 0.9629\n",
      "Test Accuracy: 96.29%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test_pca, y_test)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f19100d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>x3</th>\n",
       "      <th>y3</th>\n",
       "      <th>z3</th>\n",
       "      <th>...</th>\n",
       "      <th>z18</th>\n",
       "      <th>x19</th>\n",
       "      <th>y19</th>\n",
       "      <th>z19</th>\n",
       "      <th>x20</th>\n",
       "      <th>y20</th>\n",
       "      <th>z20</th>\n",
       "      <th>x21</th>\n",
       "      <th>y21</th>\n",
       "      <th>z21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [class, x1, y1, z1, x2, y2, z2, x3, y3, z3, x4, y4, z4, x5, y5, z5, x6, y6, z6, x7, y7, z7, x8, y8, z8, x9, y9, z9, x10, y10, z10, x11, y11, z11, x12, y12, z12, x13, y13, z13, x14, y14, z14, x15, y15, z15, x16, y16, z16, x17, y17, z17, x18, y18, z18, x19, y19, z19, x20, y20, z20, x21, y21, z21]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 64 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_pred_data = data.columns.values.tolist()\n",
    "pred_data = pd.DataFrame(columns = temp_pred_data)\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b74d8599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphabets = 'ABCDEFGHIJKLMNOPQRSTUVWXYZ'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "091b89ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "#scaler = StandardScaler()\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "def coord(image):\n",
    "    try:\n",
    "        with mp_hands.Hands(\n",
    "        static_image_mode=True,\n",
    "        max_num_hands=2,\n",
    "        min_detection_confidence=0.5) as hands:\n",
    "            image = cv2.flip(image, 1)\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_BGR2RGB)\n",
    "            image.flags.writeable = False\n",
    "            results = hands.process(image)\n",
    "            if not results.multi_hand_landmarks:\n",
    "                pass\n",
    "            image_height, image_width, _ = image.shape\n",
    "            annotated_image = image.copy()\n",
    "            for hand_landmarks in results.multi_hand_landmarks:\n",
    "                hands = results.multi_hand_landmarks[0].landmark\n",
    "                hand_row = list(np.array([[landmark.x, landmark.y, landmark.z] for landmark in hands]).flatten())\n",
    "                #pred_data.loc[0] = hand_row\n",
    "                single_sample_scaled = scaler.transform([hand_row])  # The input must be 2D for the scaler\n",
    "\n",
    "                # Reshape the sample to add the batch and time step dimensions\n",
    "                single_sample_reshaped = single_sample_scaled.reshape(1, 21, 3)\n",
    "\n",
    "                \n",
    "                return single_sample_reshaped\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3ec2379c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eda_cnn_lstm(cds):\n",
    "    # Perform PCA to reduce dimensionality\n",
    "    #pca = PCA(n_components=63)  # Maximum possible components\n",
    "    #cds_pca = pca.fit_transform(cds)\n",
    "\n",
    "    # Define new dimensions for the CNN-LSTM input\n",
    "    num_time_steps = 7  # Adjust this based on your requirements\n",
    "    height, width = 3, 3  # New dimensions that multiply to <= 63\n",
    "    channels = 1  # Grayscale\n",
    "\n",
    "    # Reshape data for CNN-LSTM input\n",
    "    cds_pca = cds.reshape(-1, num_time_steps, height, width, channels)\n",
    "    \n",
    "    return cds_pca\n",
    "\n",
    "\n",
    "def eda_cnn(cds):\n",
    "    cds_cnn = pre.reshape(1, -1) \n",
    "    return cds_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b50607f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample data for the graph\n",
    "accuracy_values = {\n",
    "    \"accuracy_cnn_lstm\": accuracy*100,       # Replace with actual accuracy value\n",
    "    \"accuracy_cnn\": accuracy_cnn*100,   # Replace with actual accuracy for CNN\n",
    "    \"accuracy_base\": accuracy_base*100   # Replace with actual baseline accuracy\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7244c518",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creating the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(accuracy_values.keys(), accuracy_values.values(), color=['blue', 'green', 'red'])\n",
    "\n",
    "plt.xlabel('Model Type')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Comparison of Model Accuracies')\n",
    "plt.ylim(0, 100)  # Set y-axis limit from 0 to 100\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "993a176e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alphabets = ['A','B','C','D','E','F','G','H','I','J','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y','Z','space','del']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a67fbecd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@180.277] global /private/var/folders/k1/30mswbxs7r1g6zwn8y4fyt500000gp/T/abs_11nitadzeg/croot/opencv-suite_1691620374638/work/modules/videoio/src/cap_gstreamer.cpp (862) isPipelinePlaying OpenCV | GStreamer warning: GStreamer: pipeline have not been created\n",
      "2024-05-29 01:08:47.775 python[66969:1472033] WARNING: AVCaptureDeviceTypeExternal is deprecated for Continuity Cameras. Please use AVCaptureDeviceTypeContinuityCamera and add NSCameraUseContinuityCameraDeviceType to your Info.plist.\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 307ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "The user is communicating:  A\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "The user is communicating:  A\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "The user is communicating:  A\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "The user is communicating:  O\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "The user is communicating:  O\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "The user is communicating:  O\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "The user is communicating:  C\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "The user is communicating:  L\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "The user is communicating:  L\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "The user is communicating:  M\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "The user is communicating:  M\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "The user is communicating:  N\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 6ms/step\n",
      "The user is communicating:  N\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 7ms/step\n",
      "The user is communicating:  C\n",
      "'NoneType' object is not iterable\n",
      "The user is communicating:  C\n",
      "'NoneType' object is not iterable\n",
      "The user is communicating:  C\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 60\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m---> 60\u001b[0m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitKey\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "cam = cv2.VideoCapture(0)\n",
    "previous = time()\n",
    "delta = 0\n",
    "s = ''\n",
    "\n",
    "while True:\n",
    "    # Get the current time, increase delta and update the previous variable\n",
    "    current = time()\n",
    "    delta += current - previous\n",
    "    previous = current\n",
    "    #t.sleep(30)\n",
    "    # Check if 3 (or some other value) seconds passed\n",
    "    if delta > 3:\n",
    "        # Operations on image\n",
    "        # Reset the time counter\n",
    "        delta = 0\n",
    "        # Show the image and keep streaming\n",
    "        _, img = cam.read()\n",
    "        cv2.imshow(\"Frame\", img)\n",
    "        \n",
    "        #print(type(cds))\n",
    "        try:\n",
    "            cds = coord(img)\n",
    "            try:\n",
    "                #print(\"entering cnn lstm\")\n",
    "                cds_cnn_lstm = eda_cnn_lstm(cds)\n",
    "                cnn_lstm_prediction = model.predict(cds_cnn_lstm)\n",
    "                predicted_index_cnn_lstm = np.argmax(cnn_lstm_prediction, axis=1)[0]\n",
    "                cnn_lstm_flag = 1\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                #print(\"entering lstm try\")\n",
    "                base_prediction = model_Base.predict(cds)\n",
    "                predicted_index_base = np.argmax(base_prediction, axis=1)[0]\n",
    "                base_flag = 1\n",
    "                \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            try:\n",
    "                #print(\"entering cnn try\")\n",
    "                cds_cnn = eda_cnn(cds)\n",
    "                cnn_prediction = model_cnn.predict(cds_cnn)\n",
    "                predicted_index_cnn = np.argmax(cnn_prediction, axis=1)[0]\n",
    "                cnn_flag = 1\n",
    "            \n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            print(\"The user is communicating: \", alphabets[predicted_index_base])\n",
    "            \n",
    "        except TypeError:\n",
    "            pass\n",
    "        except:\n",
    "            pass\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935ed3a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
